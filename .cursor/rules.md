# Regras do Projeto - TCC Sprint Final (30 dias)

## âš ï¸ MODO GUERRA - 22/01/2026 a 20/02/2026

Este arquivo contÃ©m as regras ABSOLUTAS para os prÃ³ximos 30 dias de desenvolvimento intensivo do TCC.

## ğŸ¯ Objetivo Central

Completar **TODA** a implementaÃ§Ã£o experimental, anÃ¡lise de resultados e escrita do TCC2 em 30 dias, com defesa prevista para final de fevereiro de 2026.

## ğŸš« Regras de Foco Absoluto

### Prioridade #1: TCC
- **TCC = ÃšNICA PRIORIDADE** nos prÃ³ximos 30 dias
- Nexarena â†’ **PAUSADO**
- Bot da hamburgueria â†’ **CONGELADO**
- Redes sociais â†’ **BLOQUEADO** (usar app blocker)
- YouTube/entretenimento â†’ **APENAS** apÃ³s 22:00

### Rotina de Guerra (Segunda a Sexta)
```
05:00-08:00 â†’ Academia (MANTER - saÃºde mental Ã© crÃ­tica)
08:00-15:00 â†’ EstÃ¡gio HPE (obrigatÃ³rio, nÃ£o negociÃ¡vel)
15:30-16:00 â†’ AlmoÃ§o/descanso rÃ¡pido
16:00-22:00 â†’ TCC (6h puras, ZERO distraÃ§Ã£o)
22:00-23:00 â†’ RevisÃ£o do dia + planning do prÃ³ximo
23:00-05:00 â†’ SONO (6h mÃ­nimo, NÃƒO NEGOCIÃVEL)
```

### Fins de Semana (SÃ¡bado e Domingo)
```
08:00-09:00 â†’ CafÃ© da manhÃ£
09:00-13:00 â†’ TCC (4h)
13:00-14:00 â†’ AlmoÃ§o
14:00-18:00 â†’ TCC (4h)
18:00-20:00 â†’ Descanso ativo (caminhada, famÃ­lia)
20:00-22:00 â†’ TCC (2h finais)
Total: 10h/dia nos fins de semana
```

## ğŸ“Š MÃ©tricas de Progresso

### Tracking DiÃ¡rio (OBRIGATÃ“RIO)
Ao final de cada dia, atualizar `PROGRESSO.md` com:
- [ ] Tarefas completadas
- [ ] Tarefas pendentes
- [ ] Bloqueios encontrados
- [ ] Tempo efetivo de trabalho
- [ ] NÃ­vel de energia (1-10)

### Red Flags (Alertas CrÃ­ticos)
ğŸš¨ Se qualquer um ocorrer, **PARE E REAVALIE**:
- Mais de 2 dias consecutivos sem cÃ³digo novo
- AcurÃ¡cia dos modelos < 50% (indica problema fundamental)
- GPU travando/sem memÃ³ria (otimizar ANTES de continuar)
- Walk-forward levando >12h para rodar (paralelizar)
- Sono < 5h por mais de 2 noites

## ğŸ—ï¸ Estrutura de CÃ³digo - PadrÃµes ObrigatÃ³rios

### OrganizaÃ§Ã£o de Pastas (SEGUIR ESTRITAMENTE)
```
codigo/pipeline/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Dados brutos (CSV originais)
â”‚   â”œâ”€â”€ processed/        # Dados limpos e validados
â”‚   â””â”€â”€ features/         # Dados com indicadores tÃ©cnicos
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_processing/
â”‚   â”‚   â”œâ”€â”€ load_data.py
â”‚   â”‚   â”œâ”€â”€ validate_data.py
â”‚   â”‚   â””â”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ baselines.py       # Naive, Drift
â”‚   â”‚   â”œâ”€â”€ arima_model.py
â”‚   â”‚   â”œâ”€â”€ prophet_model.py
â”‚   â”‚   â”œâ”€â”€ lstm_model.py
â”‚   â”‚   â””â”€â”€ cnn_lstm_model.py  # Modelo proposto
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ validation.py      # WalkForwardValidator
â”‚   â”‚   â”œâ”€â”€ metrics.py         # Todas as mÃ©tricas
â”‚   â”‚   â””â”€â”€ backtesting.py     # SimpleBacktest
â”‚   â”œâ”€â”€ train.py              # Script principal de treino
â”‚   â”œâ”€â”€ evaluate.py           # AvaliaÃ§Ã£o de modelos
â”‚   â””â”€â”€ backtest.py           # Backtest com custos
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ models/               # Checkpoints (.keras)
â”‚   â”œâ”€â”€ metrics/              # CSVs com resultados
â”‚   â”œâ”€â”€ plots/                # GrÃ¡ficos e visualizaÃ§Ãµes
â”‚   â””â”€â”€ logs/                 # Logs de experimentos
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploratory.ipynb     # AnÃ¡lise exploratÃ³ria
â””â”€â”€ tests/
    â””â”€â”€ test_*.py             # Testes unitÃ¡rios
```

### Nomenclatura de Arquivos
- Modelos salvos: `{modelo}_{ativo}_{fold}_{timestamp}.keras`
  - Exemplo: `cnn_lstm_PETR4_fold_03_20260125_1430.keras`
- Resultados: `{modelo}_{metrica}_{data}.csv`
  - Exemplo: `cnn_lstm_metrics_20260125.csv`
- Plots: `{tipo}_{modelo}_{ativo}.png`
  - Exemplo: `accuracy_evolution_cnn_lstm_VALE3.png`

### ConvenÃ§Ãµes de CÃ³digo
```python
# SEMPRE usar estas convenÃ§Ãµes:
# - FunÃ§Ãµes: snake_case
# - Classes: PascalCase
# - Constantes: UPPER_SNAKE_CASE
# - VariÃ¡veis: snake_case

# Exemplo:
N_STEPS = 60  # Constante
class WalkForwardValidator:  # Classe
    def __init__(self):
        self.train_size = 252 * 26  # VariÃ¡vel
        
    def get_folds(self):  # FunÃ§Ã£o
        pass
```

### Docstrings OBRIGATÃ“RIAS
```python
def create_features(df: pd.DataFrame, indicators: list) -> pd.DataFrame:
    """
    Cria indicadores tÃ©cnicos para sÃ©ries temporais intradiÃ¡rias.
    
    Conforme SeÃ§Ã£o 4.2 do TCC (Engenharia de Atributos).
    
    ParÃ¢metros:
        df: DataFrame com OHLCV (colunas: open, high, low, close, volume)
        indicators: Lista de indicadores ['ema', 'rsi', 'bollinger']
        
    Retorna:
        DataFrame com colunas originais + indicadores calculados
        
    ExceÃ§Ãµes:
        ValueError: Se df nÃ£o contiver colunas OHLCV obrigatÃ³rias
        
    Exemplo:
        >>> df = pd.read_csv('PETR4_15min.csv')
        >>> df_features = create_features(df, ['ema', 'rsi'])
    """
    # ImplementaÃ§Ã£o...
    pass
```

## ğŸ”¬ ValidaÃ§Ã£o e Testes

### Checklist Antes de Cada Commit
- [ ] CÃ³digo roda sem erros
- [ ] Docstrings estÃ£o completas
- [ ] Logs informativos estÃ£o presentes (`[OK]`, `[!]`, `[ERRO]`)
- [ ] Seeds estÃ£o fixadas (42)
- [ ] Nenhum `shuffle=True` em dados temporais
- [ ] NormalizaÃ§Ã£o aplicada APENAS no treino

### PrevenÃ§Ã£o de Data Leakage (CRÃTICO)
```python
# âŒ ERRADO - Normaliza tudo junto
scaler = MinMaxScaler()
df_normalized = scaler.fit_transform(df)

# âœ… CORRETO - Normaliza separadamente
for fold in folds:
    scaler = MinMaxScaler()
    train_scaled = scaler.fit_transform(fold['train'])  # Fit no treino
    test_scaled = scaler.transform(fold['test'])        # Transform no teste
```

### Walk-Forward OBRIGATÃ“RIO
```python
# âŒ NUNCA FAZER ISSO
from sklearn.model_selection import KFold
kfold = KFold(n_splits=5, shuffle=True)  # VIOLA ORDEM TEMPORAL!

# âœ… SEMPRE FAZER ISSO
from utils.validation import WalkForwardValidator
validator = WalkForwardValidator(
    data=df,
    train_size=252*26,  # ~1 ano
    test_size=21*26,    # ~1 mÃªs
    embargo=1           # 1 barra de embargo
)
folds = validator.get_folds()
```

## ğŸ’¾ Reprodutibilidade

### Seeds Fixadas
```python
# InÃ­cio de TODOS os scripts
import random
import numpy as np
import tensorflow as tf

SEED = 42
random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)
```

### Versionamento de DependÃªncias
Manter atualizado `requirements.txt`:
```
pandas==2.1.4
numpy==1.24.3
tensorflow-gpu==2.13.0
scikit-learn==1.3.2
optuna==3.4.0
statsmodels==0.14.0
matplotlib==3.8.2
seaborn==0.13.0
plotly==5.18.0
```

### Logging de Experimentos
```python
# SEMPRE logar configuraÃ§Ãµes
import json
from datetime import datetime

config = {
    'model': 'cnn_lstm',
    'asset': 'PETR4',
    'fold': 3,
    'hyperparameters': {
        'filters': [64, 32],
        'lstm_units': [64, 32],
        'dropout': 0.2,
        'learning_rate': 0.001
    },
    'timestamp': datetime.now().isoformat()
}

with open(f'results/logs/config_{config["timestamp"]}.json', 'w') as f:
    json.dump(config, f, indent=2)
```

## ğŸ“ˆ MÃ©tricas - Calcular TODAS

### Preditivas
```python
from utils.metrics import compute_all_metrics

metrics = compute_all_metrics(
    y_true=y_test,
    y_pred=predictions,
    y_prob=probabilities
)

# Deve retornar:
# {
#     'accuracy': float,           # AcurÃ¡cia direcional
#     'balanced_accuracy': float,  # Com ponderaÃ§Ã£o de classes
#     'f1_score': float,
#     'mcc': float,               # Matthews Correlation Coef
#     'brier_score': float,       # Qualidade probabilÃ­stica
#     'log_loss': float,
#     'auc_pr': float,            # Ãrea sob Precision-Recall
#     'ece': float                # Expected Calibration Error
# }
```

### Trading (PÃ³s-Custos)
```python
from utils.backtesting import SimpleBacktest

backtest = SimpleBacktest(
    costs={
        'corretagem': 10.0,     # R$ fixo por operaÃ§Ã£o
        'taxa': 0.0003,         # 0.03% do volume
        'slippage': 0.0001      # 0.01% de slippage
    }
)

results = backtest.run(df=test_data, signals=predictions)

# Deve retornar:
# {
#     'final_value': float,
#     'return_pct': float,
#     'sharpe_ratio': float,
#     'max_drawdown': float,
#     'profit_factor': float,
#     'turnover': float,
#     'num_trades': int
# }
```

## ğŸš¨ Alertas e Debugging

### Problemas Comuns e SoluÃ§Ãµes

#### 1. Modelo nÃ£o converge
```python
# Sintomas: Loss nÃ£o diminui, fica em ~0.69 (log(2))
# SoluÃ§Ãµes:
# - Reduzir learning rate: 0.001 â†’ 0.0001
# - Adicionar BatchNormalization
# - Simplificar arquitetura (menos camadas)
# - Verificar se labels estÃ£o balanceadas
```

#### 2. AcurÃ¡cia = 50% (chute aleatÃ³rio)
```python
# Sintomas: Modelo sempre prevÃª mesma classe
# SoluÃ§Ãµes:
# - Verificar balanceamento (usar class_weight)
# - Aumentar capacidade do modelo
# - Revisar engenharia de features
# - Checar se hÃ¡ data leakage
```

#### 3. GPU sem memÃ³ria
```python
# Sintomas: CUDA out of memory
# SoluÃ§Ãµes:
# - Reduzir batch_size: 64 â†’ 32 â†’ 16
# - Reduzir tamanho das janelas: 60 â†’ 30
# - Usar gradient_checkpointing
# - Limpar cache: tf.keras.backend.clear_session()
```

#### 4. Walk-forward muito lento
```python
# Sintomas: Cada fold leva >2h
# SoluÃ§Ãµes:
# - Paralelizar folds (joblib, multiprocessing)
# - Reduzir nÃºmero de trials do Optuna: 50 â†’ 20
# - Usar early stopping agressivo
# - Cache de features processadas
```

## ğŸ“ ComunicaÃ§Ã£o com Orientador

### ReuniÃµes Semanais
- **Quando**: Toda sexta Ã s 16:00
- **DuraÃ§Ã£o**: 30min
- **Formato**: 
  1. Progresso da semana (5min)
  2. Resultados preliminares (10min)
  3. Problemas encontrados (10min)
  4. Planejamento prÃ³xima semana (5min)

### E-mails
- **Subject**: `[TCC] - Semana X - {TÃ³pico}`
- **FrequÃªncia**: MÃ­nimo 1x por semana
- **ConteÃºdo**: 
  - Resumo executivo (3 linhas)
  - Progresso em bullet points
  - PrÃ³ximos passos
  - Anexar grÃ¡ficos/tabelas relevantes

## ğŸ“ Escrita do TCC2

### Estrutura do CapÃ­tulo de Resultados
```markdown
# 5. RESULTADOS E DISCUSSÃƒO

## 5.1 DescriÃ§Ã£o dos Dados
- EstatÃ­sticas descritivas (Tabela)
- GrÃ¡ficos de sÃ©rie temporal
- Testes de estacionariedade (ADF)

## 5.2 Desempenho Preditivo
- Tabela consolidada: Modelo Ã— MÃ©trica Ã— Ativo
- GrÃ¡ficos de acurÃ¡cia por fold
- Curvas de calibraÃ§Ã£o
- Teste Diebold-Mariano

## 5.3 Desempenho Operacional
- Backtests: Retorno, Sharpe, Drawdown
- Curvas de equity
- AnÃ¡lise de turnover

## 5.4 AnÃ¡lise de Robustez
- Resultados por regime de volatilidade
- Sensibilidade a custos
- ComparaÃ§Ã£o entre ativos

## 5.5 DiscussÃ£o
- Por que CNN-LSTM superou (ou nÃ£o) baselines?
- LimitaÃ§Ãµes do estudo
- ImplicaÃ§Ãµes prÃ¡ticas
```

### Tabelas e Figuras
- **NumeraÃ§Ã£o**: Sequencial dentro de cada capÃ­tulo
  - Exemplo: Tabela 5.1, Figura 5.2
- **Legendas**: SEMPRE abaixo (tabelas) ou abaixo (figuras)
- **Fonte**: Times New Roman 10pt para legendas
- **ReferÃªncia**: Todas devem ser citadas no texto

### CitaÃ§Ãµes (ABNT)
```
# No texto:
Conforme Vaswani et al. (2017), a arquitetura Transformer...
...mecanismo de atenÃ§Ã£o (VASWANI et al., 2017).

# Na referÃªncia:
VASWANI, A. et al. Attention is all you need. In: ADVANCES IN 
NEURAL INFORMATION PROCESSING SYSTEMS. 2017. p. 5998-6008.
```

## â±ï¸ Milestones CrÃ­ticos

### Semana 1 (22-28 Jan) - FUNDAÃ‡ÃƒO
- âœ… Dados auditados
- âœ… Features criadas
- âœ… Baselines rodando
- âœ… Walk-forward implementado

### Semana 2 (29 Jan - 04 Fev) - LSTM
- âœ… LSTM puro treinado
- âœ… Optuna rodando
- âœ… Primeiros resultados

### Semana 3 (05-11 Fev) - CNN-LSTM
- âœ… CNN-LSTM treinado
- âœ… ComparaÃ§Ã£o com baselines
- âœ… Backtests completos

### Semana 4 (12-18 Fev) - ANÃLISES
- âœ… Testes estatÃ­sticos
- âœ… Regimes de volatilidade
- âœ… Sensibilidades

### Semana 5 (19-20 Fev) - ESCRITA
- âœ… Resultados redigidos
- âœ… DiscussÃ£o completa
- âœ… RevisÃ£o final

## ğŸš€ Mantra do Projeto

```
"Feito Ã© melhor que perfeito.
ReprodutÃ­vel Ã© melhor que otimizado.
Documentado Ã© melhor que elegante.
Entregue Ã© melhor que em progresso."
```

---

**Data de InÃ­cio**: 22/01/2026  
**Data de Entrega**: 20/02/2026  
**Dias Restantes**: 30 dias  

**FOCO TOTAL. ZERO DISTRAÃ‡Ã•ES. VAMOS TERMINAR ISSO! ğŸ’ªğŸ”¥**
