# üìÖ CRONOGRAMA TCC2 - 30 DIAS DE GUERRA

**Per√≠odo**: 22 de Janeiro a 20 de Fevereiro de 2026  
**Objetivo**: Completar implementa√ß√£o, an√°lises e escrita do TCC2  
**Status**: üî¥ EM ANDAMENTO

---

## üìä Vis√£o Geral

| Semana | Per√≠odo | Foco Principal | Entreg√°veis Principais |
|--------|---------|----------------|------------------------|
| **1** | 22-28 Jan | Prepara√ß√£o & Baselines | Dados validados, Features, Naive/ARIMA rodando |
| **2** | 29 Jan-04 Fev | LSTM Puro | Modelo LSTM otimizado, Primeiros resultados |
| **3** | 05-11 Fev | CNN-LSTM H√≠brido | Modelo proposto completo, Compara√ß√µes |
| **4** | 12-18 Fev | An√°lises & Testes | Testes estat√≠sticos, Robustez, Sensibilidade |
| **5** | 19-20 Fev | Finaliza√ß√£o | Escrita completa, Revis√£o final, Slides |

---

## üóìÔ∏è SEMANA 1: PREPARA√á√ÉO DO CAMPO DE BATALHA (22-28 Jan)

### üéØ Objetivo da Semana
Garantir que a infraestrutura est√° s√≥lida: dados limpos, features criadas, baselines funcionando e walk-forward implementado.

---

### **Quarta-feira, 22/01 (DIA 1) - HOJE** üî•
**Tema**: Auditoria T√©cnica Completa

#### Bloco 1 (16:00-18:00): Organiza√ß√£o de Dados
- [x] Verificar estrutura dos dados brutos em `data/raw/`
- [x] Validar per√≠odo de cobertura (Jan/2020 - Jul/2025)
- [x] Checar missing values e gaps
- [x] Confirmar ajustes por splits/dividendos
- [x] Validar timestamps (timezone, hor√°rio de preg√£o 10h-17h)

```python
# Script: src/data_processing/validate_data.py
for ativo in ['PETR4', 'VALE3', 'ITUB4']:
    df = pd.read_csv(f'data/raw/{ativo}_M15_20200101_20251022.csv')
    print(f"\n{ativo}:")
    print(f"  Shape: {df.shape}")
    print(f"  Per√≠odo: {df['time'].min()} at√© {df['time'].max()}")
    print(f"  Missing: {df.isnull().sum().sum()}")
    print(f"  Colunas: {df.columns.tolist()}")
```

**Entreg√°vel**: Relat√≥rio de auditoria (`AUDITORIA_DADOS.md`)

#### Bloco 2 (18:00-20:00): Ambiente de Desenvolvimento
- [ ] Criar ambiente conda: `conda create -n tcc python=3.10`
- [ ] Instalar depend√™ncias essenciais
- [ ] Testar GPU (NVIDIA 1660 Super)
- [ ] Configurar TensorFlow-GPU

```bash
# Comandos
conda activate tcc
pip install pandas numpy scikit-learn
pip install tensorflow-gpu==2.13.0
pip install optuna statsmodels matplotlib seaborn plotly
python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
```

**Entreg√°vel**: Ambiente funcionando + screenshot da GPU detectada

#### Bloco 3 (20:00-22:00): Estrutura de C√≥digo
- [x] Criar estrutura de pastas conforme `.cursor/rules.md`
- [x] Organizar dados em `raw/`, `processed/`, `features/`
- [x] Criar esqueletos dos m√≥dulos principais
- [ ] Inicializar Git (se ainda n√£o feito)

**Entreg√°vel**: Estrutura completa + README.md atualizado

---

### **Quinta-feira, 23/01 (DIA 2)**
**Tema**: Engenharia de Features

#### Bloco 1 (16:00-18:00): Implementa√ß√£o de Indicadores T√©cnicos
- [x] Criar `src/data_processing/feature_engineering.py`
- [x] Implementar retornos logar√≠tmicos
- [x] Implementar MME (9, 21, 50 per√≠odos)
- [x] Implementar RSI (9, 21, 50 per√≠odos)

```python
# feature_engineering.py
def create_features(df):
    # Retornos log
    df['returns'] = np.log(df['close'] / df['close'].shift(1))
    
    # MME
    for period in [9, 21, 50]:
        df[f'ema_{period}'] = df['close'].ewm(span=period).mean()
    
    # RSI
    delta = df['close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss
    df['rsi'] = 100 - (100 / (1 + rs))
    
    return df
```

**Entreg√°vel**: Script de features testado em PETR4

#### Bloco 2 (18:00-20:00): Mais Indicadores
- [x] Implementar Bandas de Bollinger (20, 2œÉ)
- [x] Implementar volatilidade realizada (janela 20)
- [x] Criar labels com banda morta (threshold=0.0005)

```python
# Continua√ß√£o feature_engineering.py
# Bandas de Bollinger
sma_20 = df['close'].rolling(window=20).mean()
std_20 = df['close'].rolling(window=20).std()
df['bb_upper'] = sma_20 + (std_20 * 2)
df['bb_lower'] = sma_20 - (std_20 * 2)
df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / sma_20

# Volatilidade
df['volatility'] = df['returns'].rolling(window=20).std()

# Target com banda morta
df['next_return'] = df['returns'].shift(-1)
threshold = 0.0005
df['target'] = 0  # Neutro
df.loc[df['next_return'] > threshold, 'target'] = 1   # Alta
df.loc[df['next_return'] < -threshold, 'target'] = -1  # Baixa
```

**Entreg√°vel**: Dataset completo com features salvo em `data/features/`

#### Bloco 3 (20:00-22:00): An√°lise Explorat√≥ria
- [ ] Criar notebook `notebooks/exploratory.ipynb`
- [ ] Gr√°ficos de s√©rie temporal
- [ ] Distribui√ß√£o de retornos
- [ ] Correla√ß√£o entre features
- [ ] Estat√≠sticas descritivas

**Entreg√°vel**: Notebook com an√°lise explorat√≥ria completa

---

### **Sexta-feira, 24/01 (DIA 3)**
**Tema**: Baselines Naive e ARIMA

#### Bloco 1 (16:00-18:00): Baseline Naive
- [x] Implementar `src/models/baselines.py`
- [x] Classe `NaiveBaseline` (repete √∫ltimo movimento)
- [x] Classe `DriftBaseline` (tend√™ncia linear)
- [x] Testar em um ativo

```python
# baselines.py
class NaiveBaseline:
    """Assume pr√≥ximo movimento = √∫ltimo movimento"""
    def __init__(self):
        self.name = 'Naive'
    
    def predict(self, series):
        # Retorna dire√ß√£o do √∫ltimo movimento
        last_return = series.iloc[-1]
        if last_return > 0.0005:
            return 1  # Alta
        elif last_return < -0.0005:
            return -1  # Baixa
        else:
            return 0  # Neutro
```

**Entreg√°vel**: Baselines naive rodando

#### Bloco 2 (18:00-20:00): Baseline ARIMA
- [x] Implementar classe `ARIMABaseline`
- [x] Grid search para (p,d,q) otimizado por AIC
- [ ] Treinar em dados hist√≥ricos (requer statsmodels instalado)

```python
from statsmodels.tsa.arima.model import ARIMA

class ARIMABaseline:
    def __init__(self):
        self.model = None
        self.best_order = None
    
    def fit(self, train_data):
        best_aic = np.inf
        # Grid search simples
        for p in range(3):
            for d in range(2):
                for q in range(3):
                    try:
                        model = ARIMA(train_data, order=(p,d,q))
                        fitted = model.fit()
                        if fitted.aic < best_aic:
                            best_aic = fitted.aic
                            self.model = fitted
                            self.best_order = (p,d,q)
                    except:
                        continue
    
    def predict(self, steps=1):
        return self.model.forecast(steps=steps)
```

**Entreg√°vel**: ARIMA funcionando com ordem otimizada

#### Bloco 3 (20:00-22:00): Primeiras M√©tricas
- [x] Implementar `src/utils/metrics.py`
- [x] Calcular acur√°cia direcional
- [x] Calcular RMSE
- [ ] Comparar Naive vs ARIMA (aguardando walk-forward)

```python
# metrics.py
def compute_directional_accuracy(y_true, y_pred, dead_band=0.0005):
    """
    Acur√°cia com banda morta.
    Ignora movimentos neutros (|return| < threshold).
    """
    mask = np.abs(y_true) > dead_band
    y_true_filtered = (y_true[mask] > 0).astype(int)
    y_pred_filtered = (y_pred[mask] > 0).astype(int)
    
    return accuracy_score(y_true_filtered, y_pred_filtered)
```

**Entreg√°vel**: Primeiras m√©tricas calculadas e salvas

---

### **S√°bado, 25/01 (DIA 4)**
**Tema**: Walk-Forward Validation

#### Manh√£ (09:00-13:00): Implementa√ß√£o Walk-Forward
- [ ] Criar `src/utils/validation.py`
- [ ] Classe `WalkForwardValidator`
- [ ] Definir tamanhos de janelas (train=1 ano, test=1 m√™s)
- [ ] Implementar embargo temporal

```python
# validation.py
class WalkForwardValidator:
    def __init__(self, data, train_size=252*26, test_size=21*26, embargo=1):
        """
        train_size: ~1 ano de barras de 15min
        test_size: ~1 m√™s  
        embargo: 1 barra entre train/test
        """
        self.data = data
        self.train_size = train_size
        self.test_size = test_size
        self.embargo = embargo
        
    def get_folds(self):
        folds = []
        n = len(self.data)
        start = 0
        
        while start + self.train_size + self.test_size <= n:
            train_end = start + self.train_size
            test_start = train_end + self.embargo
            test_end = test_start + self.test_size
            
            folds.append({
                'train': self.data.iloc[start:train_end],
                'test': self.data.iloc[test_start:test_end],
                'fold_id': len(folds)
            })
            
            # Avan√ßa 1 m√™s
            start += self.test_size
            
        return folds
```

**Entreg√°vel**: Walk-forward funcionando

#### Tarde (14:00-18:00): Testar Walk-Forward nos Baselines
- [ ] Rodar Naive em walk-forward completo
- [ ] Rodar ARIMA em walk-forward completo
- [ ] Salvar m√©tricas por fold
- [ ] Gerar gr√°fico de acur√°cia ao longo do tempo

**Entreg√°vel**: Resultados de baselines por fold em CSV

#### Noite (20:00-22:00): An√°lise Preliminar
- [ ] Analisar evolu√ß√£o da acur√°cia
- [ ] Identificar per√≠odos problem√°ticos
- [ ] Documentar padr√µes observados

**Entreg√°vel**: Notebook com an√°lise de baselines

---

### **Domingo, 26/01 (DIA 5)**
**Tema**: Refinamento e Documenta√ß√£o

#### Manh√£ (09:00-13:00): Prophet Baseline
- [ ] Implementar `ProphetBaseline`
- [ ] Adaptar para dados intradi√°rios
- [ ] Testar sazonalidades (di√°ria)

```python
from fbprophet import Prophet

class ProphetBaseline:
    def __init__(self):
        self.model = Prophet(
            daily_seasonality=True,
            weekly_seasonality=False,
            yearly_seasonality=False
        )
    
    def fit(self, train_data):
        df = train_data[['timestamp', 'close']].rename(
            columns={'timestamp': 'ds', 'close': 'y'}
        )
        self.model.fit(df)
    
    def predict(self, periods):
        future = self.model.make_future_dataframe(periods=periods, freq='15min')
        forecast = self.model.predict(future)
        return forecast['yhat'].values[-periods:]
```

**Entreg√°vel**: Prophet funcionando

#### Tarde (14:00-18:00): Consolida√ß√£o de Resultados
- [ ] Tabela comparativa: Naive vs ARIMA vs Prophet
- [ ] Gr√°ficos de compara√ß√£o
- [ ] An√°lise de erros

**Entreg√°vel**: Relat√≥rio de baselines (`BASELINES_REPORT.md`)

#### Noite (20:00-22:00): Planejamento da Semana 2
- [ ] Revisar arquitetura LSTM
- [ ] Listar hiperpar√¢metros para Optuna
- [ ] Preparar ambiente de treino

**Entreg√°vel**: Checklist da Semana 2

---

### **Segunda-feira, 27/01 (DIA 6)**
**Tema**: Prepara√ß√£o para Deep Learning

#### Bloco 1 (16:00-18:00): Prepara√ß√£o de Dados para DL
- [ ] Criar sequ√™ncias de janelas temporais (60 barras)
- [ ] Implementar `create_sequences()`
- [ ] Normaliza√ß√£o Min-Max dentro de cada fold

```python
def create_sequences(data, n_steps=60):
    """
    Cria sequ√™ncias de janelas para LSTM.
    
    Par√¢metros:
        data: DataFrame com features
        n_steps: Tamanho da janela temporal
        
    Retorna:
        X: (n_samples, n_steps, n_features)
        y: (n_samples,)
    """
    X, y = [], []
    for i in range(len(data) - n_steps):
        X.append(data.iloc[i:i+n_steps].values)
        y.append(data.iloc[i+n_steps]['target'])
    
    return np.array(X), np.array(y)
```

**Entreg√°vel**: Pipeline de dados para LSTM

#### Bloco 2 (18:00-20:00): Arquitetura LSTM B√°sica
- [ ] Criar `src/models/lstm_model.py`
- [ ] Implementar arquitetura b√°sica (2 camadas)
- [ ] Testar compila√ß√£o e forward pass

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout

def build_lstm(input_shape, units=[64, 32], dropout=0.2, lr=0.001):
    model = Sequential([
        LSTM(units[0], return_sequences=True, input_shape=input_shape),
        Dropout(dropout),
        LSTM(units[1], return_sequences=False),
        Dropout(dropout),
        Dense(16, activation='relu'),
        Dense(1, activation='sigmoid')
    ])
    
    model.compile(
        optimizer=Adam(learning_rate=lr),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    
    return model
```

**Entreg√°vel**: LSTM compilando sem erros

#### Bloco 3 (20:00-22:00): Setup Optuna
- [ ] Criar script de otimiza√ß√£o `src/train_optuna.py`
- [ ] Definir espa√ßo de busca de hiperpar√¢metros
- [ ] Configurar study

```python
import optuna

def objective(trial):
    # Hiperpar√¢metros
    units_1 = trial.suggest_int('units_1', 32, 128, step=32)
    units_2 = trial.suggest_int('units_2', 16, 64, step=16)
    dropout = trial.suggest_float('dropout', 0.1, 0.5)
    lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)
    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])
    
    # Treinar modelo
    model = build_lstm(
        input_shape=(n_steps, n_features),
        units=[units_1, units_2],
        dropout=dropout,
        lr=lr
    )
    
    # ... c√≥digo de treino ...
    
    return val_accuracy

# Criar study
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=50)
```

**Entreg√°vel**: Optuna configurado e testado

---

### **Ter√ßa-feira, 28/01 (DIA 7)**
**Tema**: Fechamento da Semana 1

#### Bloco 1 (16:00-18:00): Testes Finais
- [ ] Rodar pipeline completo end-to-end
- [ ] Verificar reprodutibilidade (seeds)
- [ ] Checar logs e outputs

#### Bloco 2 (18:00-20:00): Documenta√ß√£o
- [ ] Atualizar README.md
- [ ] Documentar decis√µes tomadas
- [ ] Preparar apresenta√ß√£o para orientador

#### Bloco 3 (20:00-22:00): Revis√£o e Planning
- [ ] Revisar progresso da semana
- [ ] Atualizar `PROGRESSO.md`
- [ ] Planejar Semana 2 em detalhes

**Entreg√°vel**: 
- ‚úÖ Dados validados e limpos
- ‚úÖ Features criadas e testadas
- ‚úÖ Baselines (Naive, ARIMA, Prophet) funcionando
- ‚úÖ Walk-forward implementado
- ‚úÖ Ambiente de DL pronto

---

## üóìÔ∏è SEMANA 2: LSTM PURO (29 Jan - 04 Fev)

### üéØ Objetivo da Semana
Implementar, treinar e otimizar o modelo LSTM puro, gerando os primeiros resultados de deep learning.

---

### **Quarta-feira, 29/01 (DIA 8)**
**Tema**: Primeiro Treino LSTM

#### Bloco 1 (16:00-18:00): Script de Treino
- [ ] Criar `src/train.py` completo
- [ ] Implementar callbacks (EarlyStopping, ModelCheckpoint)
- [ ] Testar em 1 fold

```python
# train.py
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

# Callbacks
early_stop = EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True
)

checkpoint = ModelCheckpoint(
    filepath='results/models/lstm_{fold}_best.keras',
    monitor='val_loss',
    save_best_only=True
)

# Treino
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=100,
    batch_size=32,
    callbacks=[early_stop, checkpoint],
    verbose=1
)
```

**Entreg√°vel**: Primeiro modelo LSTM treinado

#### Bloco 2 (18:00-20:00): An√°lise do Treino
- [ ] Plotar curvas de loss
- [ ] Verificar overfitting
- [ ] Ajustar se necess√°rio

#### Bloco 3 (20:00-22:00): Walk-Forward com LSTM
- [ ] Adaptar para walk-forward
- [ ] Treinar em m√∫ltiplos folds
- [ ] Salvar checkpoints

**Entreg√°vel**: LSTM rodando em walk-forward

---

### **Quinta-feira, 30/01 (DIA 9)**
**Tema**: Otimiza√ß√£o Bayesiana

#### Bloco 1 (16:00-20:00): Optuna Rodando
- [ ] Iniciar otimiza√ß√£o com Optuna (50 trials)
- [ ] **Deixar rodando overnight**
- [ ] Monitorar progresso

```bash
# Comando para rodar
nohup python src/train_optuna.py --asset PETR4 --n_trials 50 > logs/optuna_petr4.log 2>&1 &
```

#### Bloco 2 (20:00-22:00): Monitoramento
- [ ] Verificar trials completados
- [ ] Analisar melhores hiperpar√¢metros at√© agora
- [ ] Ajustar espa√ßo de busca se necess√°rio

**Entreg√°vel**: Optuna rodando (esperado: terminar no dia seguinte)

---

### **Sexta-feira, 31/01 (DIA 10)**
**Tema**: An√°lise Optuna

#### Bloco 1 (16:00-18:00): Resultados Optuna
- [ ] Coletar melhores hiperpar√¢metros
- [ ] Salvar em `results/models/best_hyperparams_lstm.json`
- [ ] Visualizar hist√≥ria de otimiza√ß√£o

```python
# An√°lise Optuna
print("Melhores hiperpar√¢metros:", study.best_params)
print("Melhor acur√°cia:", study.best_value)

# Salvar
with open('results/models/best_hyperparams_lstm.json', 'w') as f:
    json.dump(study.best_params, f, indent=2)

# Plotar
optuna.visualization.plot_optimization_history(study)
optuna.visualization.plot_param_importances(study)
```

**Entreg√°vel**: Hiperpar√¢metros √≥timos encontrados

#### Bloco 2 (18:00-20:00): Retreinamento
- [ ] Retreinar com melhores hiperpar√¢metros
- [ ] Rodar em todos os folds do walk-forward
- [ ] Salvar modelos finais

#### Bloco 3 (20:00-22:00): M√©tricas Completas
- [ ] Calcular todas as m√©tricas (accuracy, F1, MCC, Brier, etc.)
- [ ] Comparar com baselines
- [ ] Gerar tabelas e gr√°ficos

**Entreg√°vel**: LSTM otimizado com resultados completos

---

### **S√°bado, 01/02 (DIA 11)**
**Tema**: An√°lise de Resultados LSTM

#### Manh√£ (09:00-13:00): An√°lise Profunda
- [ ] Curvas de calibra√ß√£o
- [ ] An√°lise de erros
- [ ] Casos onde LSTM falha
- [ ] Compara√ß√£o fold-a-fold com baselines

**Entreg√°vel**: Notebook de an√°lise LSTM

#### Tarde (14:00-18:00): Testes Adicionais
- [ ] Testar em VALE3 e ITUB4
- [ ] Verificar generaliza√ß√£o
- [ ] Comparar performance entre ativos

#### Noite (20:00-22:00): Documenta√ß√£o
- [ ] Atualizar `PROGRESSO.md`
- [ ] Documentar arquitetura escolhida
- [ ] Preparar relat√≥rio semanal para orientador

**Entreg√°vel**: Relat√≥rio LSTM completo

---

### **Domingo, 02/02 (DIA 12)**
**Tema**: Prepara√ß√£o CNN-LSTM

#### Manh√£ (09:00-13:00): Estudo de Arquitetura
- [ ] Revisar arquitetura CNN-LSTM do TCC
- [ ] Estudar exemplos de Conv1D para s√©ries temporais
- [ ] Planejar implementa√ß√£o

#### Tarde (14:00-18:00): Esqueleto CNN-LSTM
- [ ] Criar `src/models/cnn_lstm_model.py`
- [ ] Implementar arquitetura b√°sica
- [ ] Testar compila√ß√£o

```python
from tensorflow.keras.layers import Conv1D, MaxPooling1D

def build_cnn_lstm(input_shape, filters=[64, 32], kernel_size=3,
                   lstm_units=[64, 32], dropout=0.2, lr=0.001):
    model = Sequential([
        # Camadas Conv1D
        Conv1D(filters[0], kernel_size, activation='relu', input_shape=input_shape),
        MaxPooling1D(pool_size=2),
        Conv1D(filters[1], kernel_size, activation='relu'),
        MaxPooling1D(pool_size=2),
        
        # Camadas LSTM
        LSTM(lstm_units[0], return_sequences=True),
        Dropout(dropout),
        LSTM(lstm_units[1], return_sequences=False),
        Dropout(dropout),
        
        # Classificador
        Dense(16, activation='relu'),
        Dense(1, activation='sigmoid')
    ])
    
    model.compile(
        optimizer=Adam(learning_rate=lr),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )
    
    return model
```

**Entreg√°vel**: CNN-LSTM compilando

#### Noite (20:00-22:00): Planejamento Semana 3
- [ ] Revisar cronograma
- [ ] Listar tarefas da Semana 3
- [ ] Preparar ambiente

---

### **Segunda-feira, 03/02 (DIA 13)**
**Tema**: Primeiros Testes CNN-LSTM

#### Bloco 1 (16:00-18:00): Treino Inicial
- [ ] Treinar CNN-LSTM em 1 fold
- [ ] Comparar com LSTM puro
- [ ] Analisar curvas de aprendizado

#### Bloco 2 (18:00-20:00): Ajustes
- [ ] Ajustar arquitetura se necess√°rio
- [ ] Testar diferentes kernel_size
- [ ] Verificar capacidade do modelo

#### Bloco 3 (20:00-22:00): Preparar Optuna CNN-LSTM
- [ ] Adaptar script de otimiza√ß√£o
- [ ] Definir espa√ßo de busca (filters, kernel, lstm_units)
- [ ] Configurar study

**Entreg√°vel**: CNN-LSTM treinando, Optuna preparado

---

### **Ter√ßa-feira, 04/02 (DIA 14)**
**Tema**: Fechamento Semana 2

#### Bloco 1 (16:00-18:00): Iniciar Optuna CNN-LSTM
- [ ] Iniciar otimiza√ß√£o (deixar rodando overnight)
- [ ] Configurar monitoramento

```bash
nohup python src/train_optuna_cnn_lstm.py --asset PETR4 --n_trials 50 > logs/optuna_cnn_lstm.log 2>&1 &
```

#### Bloco 2 (18:00-20:00): Revis√£o Semanal
- [ ] Consolidar resultados LSTM
- [ ] Preparar apresenta√ß√£o para orientador
- [ ] Reuni√£o com orientador (sexta 16:00)

#### Bloco 3 (20:00-22:00): Atualiza√ß√£o
- [ ] Atualizar `PROGRESSO.md`
- [ ] Planejar Semana 3
- [ ] Revisar milestones

**Entreg√°vel**:
- ‚úÖ LSTM otimizado e avaliado
- ‚úÖ Compara√ß√£o com baselines
- ‚úÖ CNN-LSTM implementado
- ‚úÖ Optuna CNN-LSTM rodando

---

## üóìÔ∏è SEMANA 3: CNN-LSTM H√çBRIDO (05-11 Fev)

### üéØ Objetivo da Semana
Completar otimiza√ß√£o, treino e avalia√ß√£o do modelo CNN-LSTM h√≠brido (modelo proposto). Realizar backtests iniciais.

---

### **Quarta-feira, 05/02 (DIA 15)**
**Tema**: An√°lise Optuna CNN-LSTM

#### Bloco 1 (16:00-18:00): Coleta de Resultados
- [ ] Analisar trials do Optuna
- [ ] Identificar melhores hiperpar√¢metros
- [ ] Salvar configura√ß√£o √≥tima

#### Bloco 2 (18:00-20:00): Retreinamento
- [ ] Retreinar com hiperpar√¢metros √≥timos
- [ ] Validar em fold de valida√ß√£o
- [ ] Ajustar se necess√°rio

#### Bloco 3 (20:00-22:00): Walk-Forward Completo
- [ ] Iniciar walk-forward com CNN-LSTM otimizado
- [ ] Treinar em todos os folds
- [ ] Salvar checkpoints

**Entreg√°vel**: CNN-LSTM otimizado rodando

---

### **Quinta-feira, 06/02 (DIA 16)**
**Tema**: Avalia√ß√£o Completa

#### Bloco 1 (16:00-18:00): M√©tricas Preditivas
- [ ] Calcular todas as m√©tricas por fold
- [ ] Agregar resultados
- [ ] Comparar: Naive vs ARIMA vs Prophet vs LSTM vs CNN-LSTM

```python
# Tabela comparativa
models = ['Naive', 'ARIMA', 'Prophet', 'LSTM', 'CNN-LSTM']
metrics = ['Accuracy', 'F1', 'MCC', 'Brier', 'Log-Loss', 'AUC-PR']

results_df = pd.DataFrame(index=models, columns=metrics)
# Preencher com resultados...
```

**Entreg√°vel**: Tabela comparativa completa

#### Bloco 2 (18:00-20:00): Gr√°ficos
- [ ] Gr√°ficos de acur√°cia ao longo do tempo
- [ ] Box plots de m√©tricas
- [ ] Curvas de calibra√ß√£o

#### Bloco 3 (20:00-22:00): An√°lise de Erros
- [ ] Identificar per√≠odos problem√°ticos
- [ ] Analisar casos de falha
- [ ] Correlacionar com eventos de mercado

**Entreg√°vel**: An√°lise de erros documentada

---

### **Sexta-feira, 07/02 (DIA 17)**
**Tema**: Backtesting - Parte 1

#### Bloco 1 (16:00-18:00): Implementar Backtester
- [ ] Completar `src/utils/backtesting.py`
- [ ] Incluir custos de transa√ß√£o
- [ ] Implementar slippage

```python
class SimpleBacktest:
    def __init__(self, costs={'corretagem': 10, 'taxa': 0.0003, 'slippage': 0.0001}):
        self.costs = costs
    
    def run(self, df, signals, capital_inicial=100000):
        position = 0
        cash = capital_inicial
        portfolio_value = [cash]
        trades = []
        
        for i, signal in enumerate(signals):
            price = df.iloc[i]['close']
            
            # Custos
            cost_fixo = self.costs['corretagem']
            cost_prop = price * self.costs['taxa']
            price_exec = price * (1 + self.costs['slippage'] * np.sign(signal))
            
            if signal == 1 and position == 0:  # Compra
                shares = (cash - cost_fixo) / price_exec
                position = shares
                cash -= (shares * price_exec + cost_fixo)
                trades.append({'type': 'BUY', 'price': price_exec, 'shares': shares})
                
            elif signal == -1 and position > 0:  # Venda
                cash += (position * price_exec - cost_fixo - cost_prop * position * price_exec)
                trades.append({'type': 'SELL', 'price': price_exec, 'shares': position})
                position = 0
            
            total = cash + (position * price if position > 0 else 0)
            portfolio_value.append(total)
        
        return self._calculate_metrics(portfolio_value, trades)
```

**Entreg√°vel**: Backtester funcionando

#### Bloco 2 (18:00-20:00): Backtest Baselines
- [ ] Rodar backtest para Naive
- [ ] Rodar backtest para ARIMA
- [ ] Calcular m√©tricas de trading (Sharpe, Drawdown, etc.)

#### Bloco 3 (20:00-22:00): Backtest Modelos DL
- [ ] Rodar backtest para LSTM
- [ ] Rodar backtest para CNN-LSTM
- [ ] Comparar todos os modelos

**Entreg√°vel**: Backtests completos

---

### **S√°bado, 08/02 (DIA 18)**
**Tema**: An√°lise de Backtests

#### Manh√£ (09:00-13:00): M√©tricas Financeiras
- [ ] Tabela: Retorno, Sharpe, Max DD, Turnover
- [ ] Curvas de equity
- [ ] Drawdown ao longo do tempo

```python
# M√©tricas de trading
def calculate_trading_metrics(portfolio_value, trades):
    returns = pd.Series(portfolio_value).pct_change().dropna()
    
    metrics = {
        'final_value': portfolio_value[-1],
        'return_pct': (portfolio_value[-1] / portfolio_value[0] - 1) * 100,
        'sharpe_ratio': returns.mean() / returns.std() * np.sqrt(252*26),
        'max_drawdown': (pd.Series(portfolio_value) / 
                         pd.Series(portfolio_value).cummax() - 1).min() * 100,
        'num_trades': len(trades),
        'turnover': calculate_turnover(trades)
    }
    
    return metrics
```

**Entreg√°vel**: Tabela de m√©tricas financeiras

#### Tarde (14:00-18:00): An√°lise de Sensibilidade
- [ ] Testar diferentes thresholds de entrada
- [ ] Variar custos de transa√ß√£o
- [ ] Analisar impacto de slippage

#### Noite (20:00-22:00): Visualiza√ß√µes
- [ ] Gr√°ficos comparativos
- [ ] Relat√≥rio de backtest
- [ ] Documentar insights

**Entreg√°vel**: Relat√≥rio de backtests completo

---

### **Domingo, 09/02 (DIA 19)**
**Tema**: Generaliza√ß√£o e Testes Adicionais

#### Manh√£ (09:00-13:00): Outros Ativos
- [ ] Testar CNN-LSTM em VALE3
- [ ] Testar CNN-LSTM em ITUB4
- [ ] Comparar performance

#### Tarde (14:00-18:00): An√°lise Comparativa
- [ ] Performance por ativo
- [ ] Caracter√≠sticas que afetam resultado
- [ ] Documentar padr√µes

#### Noite (20:00-22:00): Consolida√ß√£o
- [ ] Atualizar `PROGRESSO.md`
- [ ] Preparar material para Semana 4
- [ ] Revisar cronograma

**Entreg√°vel**: An√°lise multi-ativos completa

---

### **Segunda-feira, 10/02 (DIA 20)**
**Tema**: Prepara√ß√£o para Testes Estat√≠sticos

#### Bloco 1 (16:00-18:00): Implementar Diebold-Mariano
- [ ] Criar fun√ß√£o para teste DM
- [ ] Preparar dados de erro

```python
from scipy import stats

def diebold_mariano_test(errors_1, errors_2):
    """
    Teste de Diebold-Mariano para comparar acur√°cia preditiva.
    
    H0: Modelos t√™m mesma acur√°cia
    H1: Modelo 1 √© diferente de Modelo 2
    """
    d = errors_1**2 - errors_2**2
    mean_d = d.mean()
    var_d = d.var()
    
    DM_stat = mean_d / np.sqrt(var_d / len(d))
    p_value = 2 * (1 - stats.norm.cdf(abs(DM_stat)))
    
    return {
        'statistic': DM_stat,
        'p_value': p_value,
        'significant': p_value < 0.05
    }
```

**Entreg√°vel**: Fun√ß√£o DM implementada

#### Bloco 2 (18:00-20:00): Preparar An√°lise de Regimes
- [ ] Implementar detector de volatilidade
- [ ] Segmentar dados por regime
- [ ] Preparar pipeline de an√°lise

```python
def detect_volatility_regime(returns, window=20, threshold=0.015):
    """
    Classifica per√≠odos em regimes de volatilidade.
    
    - Alta volatilidade: vol > threshold
    - Baixa volatilidade: vol <= threshold
    """
    vol = returns.rolling(window=window).std()
    regime = (vol > threshold).astype(int)
    regime = regime.replace({0: 'low_vol', 1: 'high_vol'})
    return regime
```

**Entreg√°vel**: Pipeline de regimes pronto

#### Bloco 3 (20:00-22:00): Documenta√ß√£o
- [ ] Documentar semana 3
- [ ] Preparar checklist Semana 4
- [ ] Revisar objetivos

---

### **Ter√ßa-feira, 11/02 (DIA 21)**
**Tema**: Fechamento Semana 3

#### Bloco 1 (16:00-18:00): Consolida√ß√£o
- [ ] Revisar todos os resultados
- [ ] Verificar reprodutibilidade
- [ ] Checar logs e outputs

#### Bloco 2 (18:00-20:00): Relat√≥rio Semanal
- [ ] Preparar slides para orientador
- [ ] Resumo executivo da semana
- [ ] Pr√≥ximos passos

#### Bloco 3 (20:00-22:00): Planning
- [ ] Atualizar `PROGRESSO.md`
- [ ] Planejar Semana 4 em detalhes
- [ ] Revisar milestones

**Entreg√°vel**:
- ‚úÖ CNN-LSTM otimizado e treinado
- ‚úÖ Compara√ß√£o completa com todos os baselines
- ‚úÖ Backtests com custos de transa√ß√£o
- ‚úÖ An√°lise multi-ativos
- ‚úÖ Prepara√ß√£o para testes estat√≠sticos

---

## üóìÔ∏è SEMANA 4: TESTES ESTAT√çSTICOS E ROBUSTEZ (12-18 Fev)

### üéØ Objetivo da Semana
Realizar testes de signific√¢ncia estat√≠stica, an√°lise de robustez por regimes de volatilidade, e an√°lises de sensibilidade.

---

### **Quarta-feira, 12/02 (DIA 22)**
**Tema**: Testes de Diebold-Mariano

#### Bloco 1 (16:00-18:00): CNN-LSTM vs Baselines
- [ ] DM: CNN-LSTM vs Naive
- [ ] DM: CNN-LSTM vs ARIMA
- [ ] DM: CNN-LSTM vs Prophet
- [ ] Salvar resultados com p-values

```python
# Exemplo de uso
errors_cnn_lstm = y_true - y_pred_cnn_lstm
errors_arima = y_true - y_pred_arima

result = diebold_mariano_test(errors_cnn_lstm, errors_arima)
print(f"DM Statistic: {result['statistic']:.4f}")
print(f"p-value: {result['p_value']:.4f}")
print(f"Significativo? {result['significant']}")
```

**Entreg√°vel**: Tabela de testes DM

#### Bloco 2 (18:00-20:00): CNN-LSTM vs LSTM
- [ ] DM: CNN-LSTM vs LSTM puro
- [ ] Analisar se CNN adiciona valor
- [ ] Documentar insights

#### Bloco 3 (20:00-22:00): Consolida√ß√£o
- [ ] Criar tabela consolidada de p-values
- [ ] Gerar gr√°fico de signific√¢ncia
- [ ] Interpretar resultados

**Entreg√°vel**: Relat√≥rio de testes estat√≠sticos

---

### **Quinta-feira, 13/02 (DIA 23)**
**Tema**: An√°lise por Regimes de Volatilidade

#### Bloco 1 (16:00-18:00): Segmenta√ß√£o
- [ ] Detectar regimes de alta/baixa volatilidade
- [ ] Segmentar dados de teste
- [ ] Calcular m√©tricas por regime

```python
# An√°lise por regime
regimes = detect_volatility_regime(returns, window=20, threshold=0.015)

for regime in ['low_vol', 'high_vol']:
    mask = regimes == regime
    y_true_regime = y_true[mask]
    y_pred_regime = y_pred[mask]
    
    metrics_regime = compute_all_metrics(y_true_regime, y_pred_regime)
    print(f"\n{regime}:")
    for metric, value in metrics_regime.items():
        print(f"  {metric}: {value:.4f}")
```

**Entreg√°vel**: M√©tricas por regime

#### Bloco 2 (18:00-20:00): Compara√ß√£o
- [ ] Tabela: Modelo √ó Regime √ó M√©trica
- [ ] Gr√°ficos comparativos
- [ ] Identificar padr√µes

#### Bloco 3 (20:00-22:00): An√°lise de Crises
- [ ] Identificar per√≠odos de crise (Mar/2020 - COVID)
- [ ] Performance durante choques
- [ ] Robustez a eventos extremos

**Entreg√°vel**: An√°lise de robustez completa

---

### **Sexta-feira, 14/02 (DIA 24)**
**Tema**: An√°lises de Sensibilidade

#### Bloco 1 (16:00-18:00): Sensibilidade a Janelas
- [ ] Testar com janelas de 5 minutos
- [ ] Testar com janelas de 30 minutos
- [ ] Comparar com baseline de 15 minutos

**Entreg√°vel**: An√°lise de granularidade temporal

#### Bloco 2 (18:00-20:00): Sensibilidade a Features
- [ ] Remover MME e retreinar
- [ ] Remover RSI e retreinar
- [ ] Remover Bollinger e retreinar
- [ ] Identificar features mais importantes

```python
# Ablation study
feature_sets = {
    'full': ['ema_9', 'ema_21', 'ema_50', 'rsi', 'bb_upper', 'bb_lower', 'volatility'],
    'no_ema': ['rsi', 'bb_upper', 'bb_lower', 'volatility'],
    'no_rsi': ['ema_9', 'ema_21', 'ema_50', 'bb_upper', 'bb_lower', 'volatility'],
    'no_bb': ['ema_9', 'ema_21', 'ema_50', 'rsi', 'volatility'],
}

for name, features in feature_sets.items():
    # Retreinar modelo...
    print(f"{name}: Accuracy = {accuracy:.4f}")
```

**Entreg√°vel**: An√°lise de import√¢ncia de features

#### Bloco 3 (20:00-22:00): Sensibilidade a Custos
- [ ] Variar corretagem (5, 10, 20 R$)
- [ ] Variar slippage (0.01%, 0.05%, 0.1%)
- [ ] Analisar breakeven

**Entreg√°vel**: An√°lise de sensibilidade a custos

---

### **S√°bado, 15/02 (DIA 25)**
**Tema**: Consolida√ß√£o de An√°lises

#### Manh√£ (09:00-13:00): Consolidar Todos os Resultados
- [ ] Revisar todas as an√°lises
- [ ] Criar tabelas consolidadas
- [ ] Gerar todos os gr√°ficos necess√°rios

**Entreg√°vel**: Pacote completo de resultados

#### Tarde (14:00-18:00): Interpreta√ß√£o
- [ ] Escrever interpreta√ß√µes
- [ ] Conectar com literatura
- [ ] Documentar limita√ß√µes

#### Noite (20:00-22:00): Prepara√ß√£o para Escrita
- [ ] Organizar materiais
- [ ] Estruturar Cap√≠tulo de Resultados
- [ ] Listar tabelas e figuras necess√°rias

**Entreg√°vel**: Estrutura do Cap√≠tulo de Resultados

---

### **Domingo, 16/02 (DIA 26)**
**Tema**: In√≠cio da Escrita

#### Manh√£ (09:00-13:00): Se√ß√£o 5.1 - Descri√ß√£o dos Dados
- [ ] Escrever estat√≠sticas descritivas
- [ ] Inserir tabelas
- [ ] Gr√°ficos de s√©ries temporais

**Entreg√°vel**: Se√ß√£o 5.1 escrita

#### Tarde (14:00-18:00): Se√ß√£o 5.2 - Desempenho Preditivo
- [ ] Escrever an√°lise de m√©tricas
- [ ] Inserir tabela comparativa
- [ ] Gr√°ficos de evolu√ß√£o

**Entreg√°vel**: Se√ß√£o 5.2 escrita

#### Noite (20:00-22:00): Continuar Escrita
- [ ] Revisar se√ß√µes escritas
- [ ] Ajustar formata√ß√£o ABNT
- [ ] Verificar cita√ß√µes

---

### **Segunda-feira, 17/02 (DIA 27)**
**Tema**: Continuar Escrita

#### Bloco 1 (16:00-18:00): Se√ß√£o 5.3 - Desempenho Operacional
- [ ] Escrever an√°lise de backtests
- [ ] Inserir tabelas de Sharpe, Drawdown
- [ ] Curvas de equity

**Entreg√°vel**: Se√ß√£o 5.3 escrita

#### Bloco 2 (18:00-20:00): Se√ß√£o 5.4 - Robustez
- [ ] Escrever an√°lise de regimes
- [ ] Inserir resultados de DM
- [ ] Sensibilidades

**Entreg√°vel**: Se√ß√£o 5.4 escrita

#### Bloco 3 (20:00-22:00): Se√ß√£o 5.5 - Discuss√£o
- [ ] Interpretar resultados
- [ ] Conectar com objetivos
- [ ] Discutir limita√ß√µes

**Entreg√°vel**: Se√ß√£o 5.5 escrita

---

### **Ter√ßa-feira, 18/02 (DIA 28)**
**Tema**: Fechamento Semana 4

#### Bloco 1 (16:00-18:00): Cap√≠tulo 6 - Conclus√£o
- [ ] Resumir contribui√ß√µes
- [ ] Trabalhos futuros
- [ ] Considera√ß√µes finais

**Entreg√°vel**: Conclus√£o escrita

#### Bloco 2 (18:00-20:00): Revis√£o Geral
- [ ] Revisar todos os cap√≠tulos
- [ ] Verificar coer√™ncia
- [ ] Ajustar transi√ß√µes

#### Bloco 3 (20:00-22:00): Formata√ß√£o
- [ ] Aplicar normas ABNT
- [ ] Verificar refer√™ncias
- [ ] Numerar tabelas e figuras

**Entreg√°vel**:
- ‚úÖ Testes estat√≠sticos completos
- ‚úÖ An√°lise de robustez
- ‚úÖ An√°lises de sensibilidade
- ‚úÖ Cap√≠tulos de Resultados e Conclus√£o escritos

---

## üóìÔ∏è SEMANA 5: FINALIZA√á√ÉO (19-20 Fev)

### üéØ Objetivo da Semana
Finalizar escrita, revisar monografia completa, preparar slides de defesa, fazer ensaio.

---

### **Quarta-feira, 19/02 (DIA 29)**
**Tema**: Revis√£o Final

#### Bloco 1 (16:00-18:00): Revis√£o ABNT
- [ ] Verificar formata√ß√£o completa
- [ ] Conferir margens, fontes, espa√ßamentos
- [ ] Revisar sum√°rio
- [ ] Verificar pagina√ß√£o

```markdown
# Checklist ABNT
- [ ] Capa
- [ ] Folha de rosto
- [ ] Resumo (PT) - m√°x 500 palavras
- [ ] Abstract (EN) - m√°x 500 palavras
- [ ] Sum√°rio autom√°tico
- [ ] Listas de figuras, tabelas, abreviaturas
- [ ] Corpo do texto: fonte 12, Times New Roman
- [ ] Legendas: fonte 10
- [ ] Margens: 3cm (esq/sup), 2cm (dir/inf)
- [ ] Espa√ßamento: 1.5 linhas
- [ ] Refer√™ncias: ABNT NBR 6023
- [ ] Cita√ß√µes: ABNT NBR 10520
```

**Entreg√°vel**: Documento formatado ABNT

#### Bloco 2 (18:00-20:00): Revis√£o de Conte√∫do
- [ ] Revisar introdu√ß√£o e objetivos
- [ ] Verificar se todos os objetivos foram atingidos
- [ ] Checar coer√™ncia entre se√ß√µes
- [ ] Revisar ortografia e gram√°tica

#### Bloco 3 (20:00-22:00): Preparar Slides
- [ ] Criar estrutura da apresenta√ß√£o (15-20 slides)
- [ ] Selecionar gr√°ficos e tabelas principais
- [ ] Escrever roteiro

```markdown
# Estrutura Slides (15-20 min)
1. Introdu√ß√£o (2 slides)
   - Contexto e motiva√ß√£o
   - Problema de pesquisa
   
2. Objetivos (1 slide)
   - Objetivo geral e espec√≠ficos
   
3. Fundamenta√ß√£o (3 slides)
   - Mercado financeiro e B3
   - LSTM e CNN
   - Walk-forward validation
   
4. Metodologia (3 slides)
   - Dados (ativos, per√≠odo, features)
   - Arquiteturas testadas
   - Protocolo experimental
   
5. Resultados (6 slides)
   - Tabela comparativa principal
   - Gr√°fico de acur√°cia ao longo tempo
   - Backtests (Sharpe, Drawdown)
   - Testes estat√≠sticos (DM)
   - An√°lise de robustez
   - S√≠ntese dos resultados
   
6. Discuss√£o (2 slides)
   - Por que CNN-LSTM superou (ou n√£o)?
   - Limita√ß√µes do estudo
   
7. Conclus√£o (2 slides)
   - Contribui√ß√µes
   - Trabalhos futuros
```

**Entreg√°vel**: Slides prontos

---

### **Quinta-feira, 20/02 (DIA 30)**
**Tema**: Entrega e Prepara√ß√£o para Defesa

#### Bloco 1 (16:00-18:00): Revis√£o Final da Monografia
- [ ] Leitura completa end-to-end
- [ ] Corrigir √∫ltimos erros
- [ ] Gerar PDF final
- [ ] Verificar hyperlinks (se aplic√°vel)

**Entreg√°vel**: PDF final pronto

#### Bloco 2 (18:00-20:00): Ensaio de Apresenta√ß√£o
- [ ] Ensaiar apresenta√ß√£o cronometrada (10-15 min)
- [ ] Ajustar timing dos slides
- [ ] Preparar respostas para perguntas esperadas

```markdown
# Perguntas Esperadas
1. Por que CNN-LSTM e n√£o Transformers?
2. Como voc√™ garante que n√£o h√° data leakage?
3. Os custos de transa√ß√£o est√£o realistas?
4. Por que a acur√°cia n√£o foi maior?
5. Qual a aplicabilidade pr√°tica?
6. Trabalhos futuros mais espec√≠ficos?
```

**Entreg√°vel**: Ensaio completo

#### Bloco 3 (20:00-22:00): Upload e Preparativos
- [ ] Fazer upload da monografia
- [ ] Enviar para orientador
- [ ] Preparar materiais auxiliares (anexos, c√≥digos)
- [ ] Fazer backup de tudo

#### Final (22:00-23:00): Celebra√ß√£o e Descanso
- [ ] Revisar jornada dos 30 dias
- [ ] Comemorar conquista! üéâ
- [ ] Descansar bem antes da defesa

**Entreg√°vel**:
- ‚úÖ Monografia ENTREGUE
- ‚úÖ Slides prontos
- ‚úÖ Ensaio feito
- ‚úÖ TCC2 COMPLETO! üéì

---

## üìà Indicadores de Sucesso

### M√©tricas de Progresso (Atualizar Diariamente)

```markdown
# PROGRESSO.md

## Semana 1: [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë] 90%
- Dados: ‚úÖ
- Features: ‚úÖ
- Baselines: ‚úÖ
- Walk-forward: ‚úÖ
- Ambiente DL: üîÑ

## Semana 2: [‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 0%
- LSTM implementado: ‚è≥
- Optuna: ‚è≥
- Resultados: ‚è≥

## Semana 3: [‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 0%
...

## Semana 4: [‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 0%
...

## Semana 5: [‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 0%
...
```

### KPIs do Projeto

| KPI | Meta | Atual | Status |
|-----|------|-------|--------|
| Dias trabalhados | 30 | 0 | üü° |
| Horas efetivas | 180h | 0h | üü° |
| Modelos implementados | 5 | 0 | üü° |
| Folds walk-forward | >10 | 0 | üü° |
| Ativos testados | 3 | 0 | üü° |
| P√°ginas escritas | 40+ | 0 | üü° |
| Tabelas/Figuras | 15+ | 0 | üü° |
| Acur√°cia CNN-LSTM | >55% | - | ‚è≥ |
| p-value DM | <0.05 | - | ‚è≥ |

---

## ‚ö†Ô∏è Plano de Conting√™ncia

### Se Atrasar >2 dias
1. **Reduzir escopo**:
   - Focar em 1 ativo principal (PETR4)
   - Reduzir trials Optuna: 50 ‚Üí 30
   - Simplificar an√°lises de sensibilidade

2. **Priorizar**:
   - CNN-LSTM > LSTM > Baselines
   - M√©tricas principais > M√©tricas secund√°rias
   - Escrita > Slides perfeitos

3. **Pedir ajuda**:
   - Comunicar orientador IMEDIATAMENTE
   - Solicitar extens√£o de prazo (se poss√≠vel)
   - Negociar redu√ß√µes de escopo

### Se Modelos N√£o Convergirem
1. Simplificar arquitetura
2. Usar hiperpar√¢metros da literatura
3. Testar em dados sint√©ticos primeiro
4. Procurar debugging em f√≥runs (Stack Overflow, Reddit)

### Se GPU Falhar
1. Usar Google Colab Pro ($10/m√™s)
2. AWS EC2 spot instances
3. Reduzir batch size drasticamente
4. Usar CPU (√∫ltimo recurso, muito lento)

---

## üéØ Mantra Final

> **"Um dia de cada vez. Um bloco de cada vez. Uma linha de c√≥digo de cada vez."**
>
> **"Progresso > Perfei√ß√£o. Entregue > Esperando. Feito > Pensando."**
>
> **"30 dias. 180 horas. 1 objetivo: TERMINAR O TCC!"**

---

**üî• COME√áAR EM: 22/01/2026 √†s 16:00**  
**üèÅ ENTREGAR EM: 20/02/2026 √†s 20:00**  
**‚è±Ô∏è TEMPO RESTANTE: 30 DIAS**

**VAMOS FAZER HIST√ìRIA! üí™üöÄüìö**
