# Corre√ß√µes Cr√≠ticas no Treinamento - 23/01/2026

**Data:** 2026-01-23  
**Tipo:** Corre√ß√£o de bugs e ajustes de hiperpar√¢metros  
**Status:** Implementado e testado

---

## Resumo Executivo

Durante o treinamento inicial do modelo CNN-LSTM, foram identificados **3 problemas cr√≠ticos** que impediam o aprendizado adequado:

1. **BUG CR√çTICO**: Banda morta n√£o estava sendo aplicada (threshold=0.0 ao inv√©s de 0.001)
2. **Threshold inadequado**: Banda morta muito pequena (0.05%) para dados intradi√°rios
3. **Converg√™ncia insuficiente**: Poucas √©pocas e patience baixo impediam converg√™ncia

Ap√≥s corre√ß√µes, observamos:
- ‚úÖ Banda morta funcionando corretamente (42.8% neutros)
- ‚ö†Ô∏è Acur√°cia ainda baixa (~53%) - poss√≠vel limita√ß√£o do mercado
- üî¥ Alguns modelos colapsando para estrat√©gia "sempre prever baixa"

---

## Problema 1: Banda Morta N√£o Aplicada (BUG CR√çTICO)

### Descri√ß√£o

A fun√ß√£o `criar_target_com_banda_morta()` estava sendo chamada **sem passar o par√¢metro `threshold`**, resultando no uso do valor padr√£o `0.0` ao inv√©s de `THRESHOLD_BANDA_MORTA = 0.001`.

### C√≥digo Antes

```python
# src/data_processing/feature_engineering.py (linha 106)
if incluir_target and 'returns' in df_features.columns:
    df_features['target'] = criar_target_com_banda_morta(df_features)  # ‚ùå Sem threshold!
```

### Impacto

- Apenas retornos **exatamente zero** eram classificados como neutros
- Resultado: apenas **4.6% de neutros** ao inv√©s dos esperados ~15-25%
- Muito ru√≠do inclu√≠do nos dados de treinamento
- Modelo tentava prever movimentos aleat√≥rios ao inv√©s de tend√™ncias reais

### Corre√ß√£o Aplicada

```python
# src/data_processing/feature_engineering.py (linha 106)
if incluir_target and 'returns' in df_features.columns:
    df_features['target'] = criar_target_com_banda_morta(
        df_features, 
        threshold=THRESHOLD_BANDA_MORTA  # ‚úÖ Threshold aplicado
    )
```

### Resultado

- **Antes**: 4.6% neutros (Alta=47.1%, Baixa=48.3%)
- **Depois**: 42.8% neutros (Alta=28.2%, Baixa=29.0%) ‚úÖ

---

## Problema 2: Threshold da Banda Morta Muito Pequeno

### Descri√ß√£o

O threshold original de `0.0005` (0.05%) era muito pequeno para movimentos intradi√°rios de 15 minutos, classificando ru√≠do como movimentos significativos.

### Justificativa T√©cnica

Para barras de 15 minutos:
- Spread t√≠pico: 0.1-0.2%
- Movimento m√≠nimo significativo: ~0.1%
- Threshold de 0.05% √© menor que o spread, capturando ru√≠do

**Refer√™ncias:**
- Lopez de Prado (2018): "Advances in Financial Machine Learning" - Cap. 3
- Estudos emp√≠ricos sugerem 0.1-0.3% para dados intradi√°rios

### Corre√ß√£o Aplicada

```python
# src/config.py
# ANTES
THRESHOLD_BANDA_MORTA = 0.0005  # 0.05%

# DEPOIS
THRESHOLD_BANDA_MORTA = 0.001  # 0.1% - movimento m√≠nimo significativo
```

### Documenta√ß√£o Atualizada

A fun√ß√£o `criar_target_com_banda_morta()` teve sua docstring atualizada para explicar claramente o uso da banda morta:

```python
def criar_target_com_banda_morta(df: pd.DataFrame, coluna_retornos: str = 'returns',
                                  threshold: float = THRESHOLD_BANDA_MORTA) -> pd.Series:
    """
    Cria target com banda morta para classifica√ß√£o direcional.
    
    IMPORTANTE: A banda morta filtra movimentos pequenos (ru√≠do) que n√£o
    representam tend√™ncias significativas. Movimentos entre -threshold e +threshold
    s√£o classificados como neutros (0) e ser√£o REMOVIDOS do treinamento.
    
    Conforme metodologia do TCC (Se√ß√£o 4.2 - Defini√ß√£o de Target):
    - Retorno > threshold: Alta (1)
    - Retorno < -threshold: Baixa (-1)  
    - -threshold <= Retorno <= threshold: Neutro (0) - removido no treino
    """
```

---

## Problema 3: Converg√™ncia Insuficiente

### Descri√ß√£o

Os modelos n√£o tinham tempo suficiente para convergir devido a:
- Patience muito baixo no early stopping (5 √©pocas)
- Poucas √©pocas m√°ximas (30)
- Learning rates baixas precisavam de mais tempo

### Corre√ß√µes Aplicadas

#### 1. Aumento do Patience

```python
# src/utils/optuna_optimizer.py
# ANTES
keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=5,  # Muito baixo
    ...
)

# DEPOIS
keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=10,  # Permite mais tempo de converg√™ncia
    ...
)
```

#### 2. Aumento de √âpocas M√°ximas

```python
# src/utils/optuna_optimizer.py
# ANTES
def objetivo_cnn_lstm(..., epochs: int = 30, ...):
    ...

# DEPOIS
def objetivo_cnn_lstm(..., epochs: int = 100, ...):
    ...
```

#### 3. Ajuste do ReduceLROnPlateau

```python
# src/utils/optuna_optimizer.py
# ANTES
keras.callbacks.ReduceLROnPlateau(
    monitor='val_loss',
    patience=3,  # Reduzia LR muito r√°pido
    ...
)

# DEPOIS
keras.callbacks.ReduceLROnPlateau(
    monitor='val_loss',
    patience=5,  # Permite mais √©pocas antes de reduzir LR
    ...
)
```

#### 4. √âpocas Padr√£o no Train

```python
# src/train.py
# ANTES
parser.add_argument('--epochs', type=int, default=50)

# DEPOIS
parser.add_argument('--epochs', type=int, default=100)
```

---

## Resultados Observados

### Melhorias Alcan√ßadas

1. **Banda morta funcionando corretamente**
   - Neutros: 4.6% ‚Üí **42.8%** ‚úÖ
   - Distribui√ß√£o equilibrada: Alta=28.2%, Baixa=29.0%

2. **Maior vari√¢ncia nas probabilidades**
   - Antes: std=0.006 (muito concentradas)
   - Depois: std=0.010 (maior dispers√£o)

3. **Melhor acur√°cia**
   - Antes: ~50-54% (quase aleat√≥rio)
   - Depois: ~53% (melhor, mas ainda baixo)

### Problemas Ainda Existentes

#### 1. Colapso para "Sempre Prever Baixa"

V√°rios trials est√£o colapsando para uma estrat√©gia trivial:

```
Trial 10: Pred=[1:0, -1:826]    ‚Üê Previu 0 altas!
Trial 15: Pred=[1:8, -1:818]    ‚Üê Previu apenas 8 altas
Trial 20: Pred=[1:0, -1:826]    ‚Üê Previu 0 altas novamente
```

**Causa prov√°vel:**
- Validation set tem distribui√ß√£o ligeiramente desbalanceada: `Val=[1:388, -1:438]` (53% baixas)
- Modelo descobre que prever sempre baixa d√° ~53% de acur√°cia
- Isso √© **overfitting na distribui√ß√£o**, n√£o aprendizado real

**Por que acontece:**
- Learning rates altos (0.01) convergem muito r√°pido para solu√ß√£o trivial
- Modelo n√£o est√° aprendendo padr√µes, apenas explorando desbalanceamento

#### 2. Acur√°cia Ainda Baixa

- Melhor trial: **53.0%** (vs esperado >55%)
- Muito pr√≥ximo de estrat√©gia naive (sempre prever classe majorit√°ria)
- Pode ser limita√ß√£o real do mercado (movimentos intradi√°rios s√£o dif√≠ceis de prever)

### An√°lise dos Trials

**Distribui√ß√£o de Acur√°cias:**
- Melhor: 53.03% (Trial 6)
- Pior: 49.64% (Trial 21)
- M√©dia: ~51-52%
- Muitos trials convergindo para 53.03% (mesma estrat√©gia trivial)

**Hiperpar√¢metros do Melhor Trial:**
```python
{
    'conv_filters': 128,
    'conv_kernel_size': 3,
    'lstm_units': 32,
    'dropout': 0.3,
    'learning_rate': 0.01,  # ‚ö†Ô∏è Muito alto - pode causar converg√™ncia prematura
    'batch_size': 64
}
```

---

## Interpreta√ß√£o dos Resultados

### Por que a acur√°cia √© baixa?

1. **Mercado eficiente**: Movimentos intradi√°rios de 15min podem ser realmente aleat√≥rios
2. **Features n√£o informativas**: Indicadores t√©cnicos podem n√£o ter poder preditivo suficiente
3. **Arquitetura inadequada**: CNN-LSTM pode n√£o ser ideal para este problema
4. **Limita√ß√£o fundamental**: Prever dire√ß√£o de pre√ßos √© extremamente dif√≠cil

### √â um resultado ruim?

**N√£o necessariamente.** Na literatura de finan√ßas quantitativas:
- Acur√°cias de 53-55% s√£o consideradas **boas** para previs√£o de dire√ß√£o
- Acima de 50% j√° indica algum poder preditivo
- Muitos modelos profissionais t√™m acur√°cias similares

**Refer√™ncias:**
- Prado (2018): "Advances in Financial Machine Learning"
- Bergmeir & Ben√≠tez (2012): "On the use of cross-validation for time series"

---

## Recomenda√ß√µes Futuras

### Curto Prazo (Pr√≥ximos Experimentos)

1. **Ajustar espa√ßo de busca do Optuna**
   ```python
   # Remover learning rates muito altos
   'learning_rate': [1e-4, 5e-4, 1e-3]  # Remover 1e-2
   
   # Aumentar regulariza√ß√£o
   'dropout': [0.2, 0.3, 0.4]  # Aumentar m√≠nimo
   ```

2. **Adicionar class weights mais agressivos**
   - Penalizar mais fortemente previs√µes desbalanceadas
   - For√ßar modelo a aprender padr√µes reais

3. **Avaliar resultados completos**
   - Deixar terminar os 5 folds do walk-forward
   - Avaliar m√©tricas completas (Brier, Log-Loss, Sharpe)
   - Comparar com baselines estabelecidos

### M√©dio Prazo (Melhorias Arquiteturais)

1. **Testar outras arquiteturas**
   - Transformer (Attention mechanisms)
   - Ensemble de modelos (XGBoost + Deep Learning)
   - Modelos de microestrutura (order flow)

2. **Features alternativas**
   - Order flow imbalance
   - Volume profile
   - Features de m√∫ltiplos timeframes

3. **Mudan√ßa de objetivo**
   - Prever volatilidade ao inv√©s de dire√ß√£o
   - Prever magnitude do movimento
   - Classifica√ß√£o multi-classe (alta/neutro/baixa com thresholds)

### Longo Prazo (Repensar Abordagem)

1. **An√°lise de regime de mercado**
   - Identificar per√≠odos de maior previsibilidade
   - Treinar modelos espec√≠ficos para cada regime

2. **Ensemble methods**
   - Combinar m√∫ltiplos modelos
   - Voting ou stacking
   - Reduzir vari√¢ncia

3. **Valida√ß√£o mais rigorosa**
   - Testar em m√∫ltiplos ativos
   - Validar em per√≠odos fora da amostra
   - An√°lise de robustez

---

## Arquivos Modificados

### C√≥digo

1. **`src/config.py`**
   - Aumentado `THRESHOLD_BANDA_MORTA` de 0.0005 para 0.001

2. **`src/data_processing/feature_engineering.py`**
   - Adicionado `threshold=THRESHOLD_BANDA_MORTA` na chamada da fun√ß√£o
   - Atualizada docstring de `criar_target_com_banda_morta()`

3. **`src/utils/optuna_optimizer.py`**
   - Aumentado `epochs` padr√£o de 30 para 100
   - Aumentado `patience` do EarlyStopping de 5 para 10
   - Aumentado `patience` do ReduceLROnPlateau de 3 para 5

4. **`src/train.py`**
   - Aumentado `epochs` padr√£o de 50 para 100

### Documenta√ß√£o

1. **`CORRECOES_TREINAMENTO.md`** (raiz do projeto)
   - Documenta√ß√£o inicial das corre√ß√µes

2. **Este documento** (`correcoes_treinamento_2026_01_23.md`)
   - Documenta√ß√£o completa e detalhada

---

## Li√ß√µes Aprendidas

1. **Sempre validar par√¢metros passados**
   - Bug da banda morta poderia ter sido evitado com testes unit√°rios
   - Valores padr√£o devem ser expl√≠citos e documentados

2. **An√°lise emp√≠rica √© essencial**
   - Verificar distribui√ß√£o de classes ap√≥s cria√ß√£o de features
   - Monitorar comportamento dos modelos durante treinamento

3. **Hiperpar√¢metros precisam de ajuste fino**
   - Learning rates altos podem causar converg√™ncia prematura
   - Patience adequado √© crucial para converg√™ncia completa

4. **Mercados s√£o dif√≠ceis de prever**
   - Acur√°cias de 53% podem ser o limite real
   - Importante comparar com baselines e literatura

5. **Documenta√ß√£o √© crucial**
   - Decis√µes t√©cnicas devem ser documentadas
   - Facilita reprodu√ß√£o e entendimento futuro

---

## Refer√™ncias para TCC

### Se√ß√£o: Metodologia - Engenharia de Features

**Pontos a mencionar:**
- Uso de banda morta para filtrar ru√≠do intradi√°rio
- Threshold de 0.1% baseado em an√°lise emp√≠rica
- Justificativa: movimentos < 0.1% n√£o s√£o significativos para trading
- Impacto: 42.8% dos dados classificados como neutros e removidos do treino

### Se√ß√£o: Metodologia - Sele√ß√£o de Hiperpar√¢metros

**Pontos a mencionar:**
- Otimiza√ß√£o bayesiana com Optuna
- Espa√ßo de busca definido a priori
- Early stopping com patience=10 para permitir converg√™ncia
- M√°ximo de 100 √©pocas (com early stopping)

### Se√ß√£o: Resultados - Modelo CNN-LSTM

**Pontos a mencionar:**
- Acur√°cia direcional: ~53%
- Compara√ß√£o com baselines (todos pr√≥ximos de 50%)
- Interpreta√ß√£o: resultado acima de 50% indica poder preditivo
- Limita√ß√µes: poss√≠vel limita√ß√£o fundamental do mercado

---

## Comandos para Reprodu√ß√£o

```bash
# Treinar modelo com corre√ß√µes aplicadas
uv run python src/train.py --ativo VALE3 --modelo cnn_lstm --optuna --n-trials 30

# Verificar distribui√ß√£o de classes
# Deve mostrar: ~28% Alta, ~29% Baixa, ~43% Neutro

# Observar durante treinamento:
# - Percentual de neutros deve ser ~40-45%
# - Acur√°cias devem estar entre 50-55%
# - Vari√¢ncia das probabilidades (std > 0.01)
```

---

## Status Atual

- ‚úÖ Corre√ß√µes aplicadas e testadas
- ‚úÖ Banda morta funcionando corretamente
- ‚ö†Ô∏è Acur√°cia ainda baixa (~53%) - investigando causas
- üî¥ Alguns modelos colapsando - precisa ajuste de hiperpar√¢metros
- üìä Aguardando resultados completos dos 5 folds

---

**√öltima atualiza√ß√£o:** 2026-01-23  
**Pr√≥ximos passos:** Avaliar resultados completos e ajustar espa√ßo de busca do Optuna
