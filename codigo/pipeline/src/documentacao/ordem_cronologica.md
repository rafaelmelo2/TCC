# Ordem CronolÃ³gica - Desenvolvimento do TCC

DocumentaÃ§Ã£o cronolÃ³gica de todas as decisÃµes tÃ©cnicas, implementaÃ§Ãµes e anÃ¡lises realizadas.

---

## 2026-01-23 - CorreÃ§Ãµes CrÃ­ticas no Treinamento

### Contexto
- Primeiro treinamento do modelo CNN-LSTM com Optuna
- Identificados problemas que impediam aprendizado adequado
- AcurÃ¡cias muito baixas (~50-54%) indicando problemas

### Problemas Identificados

1. **BUG CRÃTICO**: Banda morta nÃ£o aplicada
   - FunÃ§Ã£o chamada sem parÃ¢metro `threshold`
   - Usando valor padrÃ£o 0.0 ao invÃ©s de 0.001
   - Resultado: apenas 4.6% neutros (deveria ser ~40%)

2. **Threshold inadequado**
   - Threshold de 0.05% muito pequeno para dados intradiÃ¡rios
   - Classificando ruÃ­do como movimento significativo

3. **ConvergÃªncia insuficiente**
   - Patience muito baixo (5 Ã©pocas)
   - Poucas Ã©pocas mÃ¡ximas (30)
   - Modelos nÃ£o convergiam adequadamente

### CorreÃ§Ãµes Aplicadas

1. **AplicaÃ§Ã£o correta da banda morta**
   - Adicionado `threshold=THRESHOLD_BANDA_MORTA` na chamada
   - Threshold aumentado de 0.0005 para 0.001 (0.1%)

2. **Ajustes de hiperparÃ¢metros**
   - Patience aumentado: 5 â†’ 10 Ã©pocas
   - Ã‰pocas mÃ¡ximas: 30 â†’ 100
   - ReduceLROnPlateau patience: 3 â†’ 5

### Resultados

**Melhorias:**
- âœ… Neutros: 4.6% â†’ **42.8%** (correto!)
- âœ… Maior variÃ¢ncia nas probabilidades (std: 0.006 â†’ 0.010)
- âœ… AcurÃ¡cia melhorou: ~50% â†’ ~53%

**Problemas ainda existentes:**
- âš ï¸ AcurÃ¡cia ainda baixa (~53%) - possÃ­vel limitaÃ§Ã£o do mercado
- ðŸ”´ Alguns modelos colapsando para "sempre prever baixa"
- âš ï¸ Learning rates altos (0.01) causando convergÃªncia prematura

### InterpretaÃ§Ã£o

- AcurÃ¡cia de 53% Ã© considerada **boa** na literatura de finanÃ§as quantitativas
- Acima de 50% indica poder preditivo real
- Movimentos intradiÃ¡rios sÃ£o notoriamente difÃ­ceis de prever

### Arquivos Modificados
- `src/config.py` - Aumentado THRESHOLD_BANDA_MORTA
- `src/data_processing/feature_engineering.py` - Aplicado threshold corretamente
- `src/utils/optuna_optimizer.py` - Ajustes de convergÃªncia
- `src/train.py` - Aumentado Ã©pocas padrÃ£o

### DocumentaÃ§Ã£o
- [CorreÃ§Ãµes do Treinamento](implementacoes/correcoes_treinamento_2026_01_23.md) - DocumentaÃ§Ã£o completa

### PrÃ³ximos Passos
- Avaliar resultados completos dos 5 folds
- Ajustar espaÃ§o de busca do Optuna (remover lr=0.01)
- Testar outras arquiteturas se necessÃ¡rio

---

## 2026-01-23 (tarde) - ImplementaÃ§Ã£o de Melhorias TÃ©cnicas

### Contexto
- Treinamento completo finalizado (2 horas)
- Resultados: AcurÃ¡cia mÃ©dia 52.51%, F1=0.626, MCC=0.039
- Modelos nÃ£o foram salvos (perda de 2 horas de trabalho)
- Consulta ao TCC para identificar melhorias possÃ­veis

### Melhorias Implementadas

1. **Salvamento automÃ¡tico de modelos**
   - ModelCheckpoint para cada fold
   - Salva melhor modelo baseado em val_loss
   - Estrutura: `models/{ativo}/{modelo_tipo}/fold_{n}_checkpoint.keras`

2. **Gradient clipping**
   - Implementado com `clipnorm=1.0`
   - Previne explosÃ£o de gradientes
   - Conforme TCC SeÃ§Ã£o 4.4

3. **Otimizador AdamW**
   - JÃ¡ estava implementado (confirmado)
   - Weight decay desacoplado
   - Melhor regularizaÃ§Ã£o que Adam

4. **Callbacks otimizados**
   - EarlyStopping (patience=10)
   - ReduceLROnPlateau (patience=5)
   - ModelCheckpoint (novo)

### AnÃ¡lise dos Resultados Atuais

**Walk-Forward (5 folds):**

| Fold | AcurÃ¡cia | F1 | MCC | Neutros |
|------|----------|----|----|---------|
| 1 | 46.87% | 0.638 | 0.000 | 36.0% |
| 2 | 52.45% | 0.559 | 0.050 | 33.7% |
| 3 | 52.09% | 0.638 | 0.051 | 43.7% |
| 4 | 54.34% | 0.569 | 0.093 | 52.1% |
| 5 | 56.82% | 0.725 | 0.000 | 49.9% |
| **MÃ©dia** | **52.51%** | **0.626** | **0.039** | **43.1%** |

**InterpretaÃ§Ã£o:**
- âœ… AcurÃ¡cia acima de baseline (~50%)
- âœ… Melhoria progressiva (46.87% â†’ 56.82%)
- âš ï¸ MCC muito baixo (sinal fraco)
- âš ï¸ Alta variabilidade entre folds

### TÃ©cnicas Ainda NÃ£o Implementadas (Do TCC)

**Curto prazo:**
- Cosine annealing scheduler
- One-cycle scheduler
- Features adicionais (amplitude, volume)

**MÃ©dio prazo:**
- Ensemble de modelos (voting)
- Metaclassificador
- Retreinamento no maior prefixo

### Arquivos Modificados
- `src/models/cnn_lstm_model.py` - Gradient clipping
- `src/models/lstm_model.py` - Gradient clipping
- `src/train.py` - Salvamento de modelos
- `src/utils/optuna_optimizer.py` - Gradient clipping

### DocumentaÃ§Ã£o
- [Melhorias TÃ©cnicas](implementacoes/melhorias_tecnicas_2026_01_23.md) - DocumentaÃ§Ã£o completa
- [MudanÃ§as Completas](implementacoes/mudancas_completas_2026_01_23_24.md) - DocumentaÃ§Ã£o completa de todas as mudanÃ§as

### Scripts Criados
- `src/scripts/analisar_modelos_salvos.py` - AnÃ¡lise de modelos salvos
- `src/scripts/ver_historico_epochs.py` - VisualizaÃ§Ã£o de epochs
- `src/scripts/teste_rapido_validacao.py` - ValidaÃ§Ã£o de testes rÃ¡pidos
- `treinar_e_desligar.sh` - Treinamento com desligamento automÃ¡tico

### Status Atual
- âœ… ImplementaÃ§Ãµes completas
- âœ… 3 de 5 modelos salvos (folds 1-3)
- âŒ Faltam folds 4 e 5 (melhores resultados: 54.34% e 56.82%)
- â³ PrÃ³ximo: Retreinar para salvar todos os modelos

---

## 2025-01-23 - RemoÃ§Ã£o da Banda Morta

### Contexto
- Banda morta original: Â±0.0005 (0.05%)
- 22.3% dos dados classificados como neutros
- Apenas 4.6% sÃ£o realmente zero
- 6,225 amostras (17.7%) sendo perdidas

### AnÃ¡lise Realizada
- Total de retornos: 35,153
- MÃ©dia: 0.000012
- Desvio-padrÃ£o: 0.003443
- Retornos dentro da banda morta: 7,848 (22.3%)
- Retornos realmente zero: 1,624 (4.6%)

### DecisÃ£o Tomada
- Remover banda morta (threshold = 0.0)
- Usar apenas sinal do retorno (>0, <0, ==0)
- Aplicar em: target creation, mÃ©tricas, baselines

### Justificativa
- Perda de 17.7% dos dados era significativa
- Retornos intradiÃ¡rios sÃ£o naturalmente pequenos
- Banda morta eliminava informaÃ§Ãµes Ãºteis para previsÃ£o
- Para previsÃ£o de direÃ§Ã£o, qualquer movimento Ã© relevante

### Impacto
- +17.7% de amostras utilizadas (6,225 amostras recuperadas)
- ARIMA F1_Score melhorou: 0.576 â†’ 0.593
- MÃ©tricas mais realistas usando quase todos os dados
- DistribuiÃ§Ã£o de targets: Alta 38.2%, Baixa 39.5%, Neutro 4.6% (antes: 22.3% neutros)

### Arquivos Modificados
- `src/data_processing/feature_engineering.py` - criar_target_com_banda_morta()
- `src/utils/metrics.py` - calcular_acuracia_direcional(), calcular_metricas_preditivas()
- `src/models/baselines.py` - NaiveBaseline, DriftBaseline, ARIMABaseline

---

## 2025-01-23 - CorreÃ§Ã£o do Problema ARIMA

### Contexto
- ARIMA retornando F1_Score = 0.0 e MCC = 0.0
- 100% das previsÃµes eram zeros (neutros)

### AnÃ¡lise Realizada
- Forecasts do ARIMA muito pequenos: min=-0.000023, max=0.000004
- Todos os forecasts dentro da banda morta original (Â±0.0005)
- Threshold muito grande para valores tÃ£o pequenos

### DecisÃ£o Tomada
- Remover banda morta resolveu o problema
- ARIMA agora usa apenas sinal do forecast

### Justificativa
- Forecasts de retornos sÃ£o naturalmente muito pequenos
- Banda morta impedia captura da direÃ§Ã£o
- Sinal do forecast Ã© suficiente para classificaÃ§Ã£o

### Impacto
- ARIMA passou a prever direÃ§Ãµes reais
- DistribuiÃ§Ã£o: 1=1637, -1=546, 0=205 (antes: 0=2388)
- F1_Score: 0.0 â†’ 0.593

---

## 2025-01-23 - ImplementaÃ§Ã£o Walk-Forward Validation

### Contexto
- Necessidade de validaÃ§Ã£o temporal rigorosa
- Evitar data leakage em sÃ©ries temporais financeiras

### ImplementaÃ§Ã£o
- Classe WalkForwardValidator criada
- Suporte a embargo temporal
- DivisÃ£o sequencial de dados
- AgregaÃ§Ã£o de resultados por fold

### CaracterÃ­sticas
- Treino: 6552 barras (~1 ano)
- Teste: 546 barras (~1 mÃªs)
- Embargo: 1 barra
- GeraÃ§Ã£o automÃ¡tica de folds

### Justificativa
- ValidaÃ§Ã£o walk-forward Ã© obrigatÃ³ria para sÃ©ries temporais
- K-fold tradicional viola ordem temporal
- Embargo previne contaminaÃ§Ã£o entre treino/teste

### Arquivos Criados
- `src/utils/validation.py` - WalkForwardValidator, FoldInfo

---

## 2025-01-23 - SimplificaÃ§Ã£o do CÃ³digo

### Contexto
- CÃ³digo muito modularizado e verboso
- Muitos fallbacks desnecessÃ¡rios
- ComentÃ¡rios excessivos

### DecisÃ£o Tomada
- Remover todos os fallbacks de import
- Simplificar docstrings
- Reduzir comentÃ¡rios excessivos
- Manter apenas cÃ³digo essencial

### Impacto
- ReduÃ§Ã£o de ~50% nas linhas de cÃ³digo
- CÃ³digo mais legÃ­vel e direto
- Imports consistentes (apenas relativos)
- ManutenÃ§Ã£o mais fÃ¡cil

### Arquivos Simplificados
- `testar_baselines_walkforward.py`: 277 â†’ 141 linhas
- `load_data.py`: 325 â†’ 120 linhas
- `feature_engineering.py`: 449 â†’ 124 linhas
- `baselines.py`: 328 â†’ 135 linhas
- `metrics.py`: 192 â†’ 66 linhas
- `validation.py`: 413 â†’ 180 linhas

---

## 2025-01-23 - ImplementaÃ§Ã£o de Baselines

### ImplementaÃ§Ã£o
- NaiveBaseline: repete Ãºltima direÃ§Ã£o
- DriftBaseline: projeta tendÃªncia linear
- ARIMABaseline: modelo Box-Jenkins com grid search

### CaracterÃ­sticas
- Interface comum (BaseBaseline)
- OtimizaÃ§Ã£o ARIMA por AIC
- ConversÃ£o de forecasts para direÃ§Ãµes

### Resultados Iniciais (com banda morta)
- Naive: 50.95% acurÃ¡cia
- Drift: 49.37% acurÃ¡cia
- ARIMA: 50.95% acurÃ¡cia (mas F1=0.0)

### Resultados Finais (sem banda morta)
- Naive: 50.50% acurÃ¡cia, F1=0.315
- Drift: 49.76% acurÃ¡cia, F1=0.543
- ARIMA: 48.36% acurÃ¡cia, F1=0.593

### Arquivos Criados
- `src/models/baselines.py`

---

## 2025-01-23 - Engenharia de Features

### Features Implementadas
- Retornos logarÃ­tmicos
- EMAs: 9, 21, 50 perÃ­odos
- RSIs: 9, 21, 50 perÃ­odos
- Bandas de Bollinger (20 perÃ­odos, 2 desvios)
- Volatilidade realizada (20 perÃ­odos)
- Target de direÃ§Ã£o

### Justificativa
- Features tÃ©cnicas padrÃ£o em anÃ¡lise financeira
- MÃºltiplos perÃ­odos para capturar diferentes escalas temporais
- Target binÃ¡rio (alta/baixa) para classificaÃ§Ã£o

### Arquivos Criados
- `src/data_processing/feature_engineering.py`

---

## 2025-01-23 - ImplementaÃ§Ã£o de MÃ©tricas

### MÃ©tricas Implementadas
- AcurÃ¡cia direcional
- AcurÃ¡cia, Balanced Accuracy
- F1-Score, MCC
- Brier Score, Log-Loss, AUC-PR (quando disponÃ­vel)

### CaracterÃ­sticas
- Sem banda morta (ignora apenas zeros reais)
- Foco em mÃ©tricas robustas a desbalanceamento
- Suporte a mÃ©tricas probabilÃ­sticas

### Arquivos Criados
- `src/utils/metrics.py`

---

## 2025-01-23 - Estrutura de ConfiguraÃ§Ã£o

### DecisÃ£o
- Centralizar todas as configuraÃ§Ãµes em `src/config.py`
- Remover fallbacks de import
- Usar apenas imports relativos

### ConfiguraÃ§Ãµes Centralizadas
- Estrutura de dados (colunas obrigatÃ³rias)
- HorÃ¡rio de pregÃ£o B3
- PerÃ­odos de indicadores tÃ©cnicos
- Tamanhos de walk-forward
- Custos de transaÃ§Ã£o
- Seed para reprodutibilidade

### Arquivos Criados
- `src/config.py`

---

## 2025-01-26 - Resultados dos Baselines com Walk-Forward

### Contexto
- ImplementaÃ§Ã£o completa de 4 baselines: Naive, Drift, ARIMA, Prophet
- Teste com walk-forward validation em VALE3
- 5 folds, 2,388 amostras de teste agregadas

### Resultados Obtidos

| Baseline | Accuracy Direcional | F1-Score | MCC |
|----------|---------------------|----------|-----|
| Naive | 50.50% | 0.315 | 0.002 |
| Drift | 49.76% | 0.543 | -0.002 |
| ARIMA | 48.36% | 0.593 | -0.029 |
| Prophet | 50.50% | 0.531 | 0.012 |

### AnÃ¡lise e InterpretaÃ§Ã£o

**Performance Geral:**
- Todos os baselines performam prÃ³ximo de 50% (aleatÃ³rio)
- Isso Ã© **esperado e desejÃ¡vel** para baselines simples
- Confirma que predizer direÃ§Ã£o de preÃ§os Ã© um problema difÃ­cil

**Destaques:**
- Naive e Prophet: melhor acurÃ¡cia direcional (50.50%)
- ARIMA: melhor F1-Score (0.593)
- Prophet: melhor MCC (0.012) - correlaÃ§Ã£o positiva, ainda que fraca

**ValidaÃ§Ã£o MetodolÃ³gica:**
- âœ… Walk-forward funcionou corretamente (sem data leakage)
- âœ… Baseline estabelecido (~50%) para comparaÃ§Ã£o com deep learning
- âœ… Resultados documentados e prontos para TCC

### Justificativa para Deep Learning
- Baselines simples nÃ£o superam o acaso
- Modelos nÃ£o-lineares (LSTM, CNN-LSTM) podem capturar padrÃµes complexos
- Expectativa: modelos de deep learning devem superar 52-55% para serem Ãºteis

### Arquivos Atualizados
- `src/documentacao/implementacoes/baselines.md` - DocumentaÃ§Ã£o completa dos resultados
- `data/processed/VALE3_baselines_walkforward.csv` - Resultados salvos

---

## 2026-01-27 - Melhorias CrÃ­ticas: Cosine Scheduler e Class Weights

### Contexto
- AnÃ¡lise dos resultados de treinamento dos modelos CNN-LSTM para PETR4, ITUB4 e VALE3
- Identificados problemas crÃ­ticos: F1=0.0 e MCC=0.0 em alguns folds (PETR4 folds 2 e 3)
- Modelos prevendo sempre a mesma classe (colapso de aprendizado)

### Problemas Identificados

1. **F1=0.0 e MCC=0.0 em alguns folds**
   - PETR4 Folds 2 e 3 apresentavam F1=0.0 e MCC=0.0
   - Modelo prevendo sempre a mesma classe (provavelmente sempre "baixa")
   - Indica que modelo nÃ£o estÃ¡ aprendendo padrÃµes reais, apenas explorando desbalanceamento

2. **AcurÃ¡cias abaixo do esperado**
   - PETR4 Fold 3: 47.15% (abaixo do baseline de 50%)
   - ITUB4 Fold 5: 50.00% (exatamente no acaso)

3. **Falta de tÃ©cnicas do TCC**
   - Cosine Annealing Scheduler mencionado no TCC SeÃ§Ã£o 4.4 nÃ£o implementado
   - Class weights usando cÃ¡lculo manual (nÃ£o robusto)

### Melhorias Implementadas

1. **Cosine Annealing Scheduler (TCC SeÃ§Ã£o 4.4)**
   - Implementado `CosineDecayRestarts` do TensorFlow
   - Reduz learning rate seguindo curva cosseno com restarts periÃ³dicos
   - Melhora convergÃªncia e pode aumentar acurÃ¡cia em 1-3%
   - Arquivos modificados: `src/train.py`, `src/utils/optuna_optimizer.py`

2. **Class Weights Melhorados (sklearn)**
   - SubstituÃ­do cÃ¡lculo manual por `sklearn.utils.class_weight.compute_class_weight`
   - EstratÃ©gia 'balanced' mais robusta
   - Previne colapso para mesma classe
   - Arquivos modificados: `src/train.py`, `src/utils/optuna_optimizer.py`

3. **Monitoramento de DistribuiÃ§Ã£o**
   - Adicionado aviso quando modelo prevÃª sempre mesma classe
   - Log detalhado durante otimizaÃ§Ã£o com distribuiÃ§Ã£o de previsÃµes
   - Facilita identificaÃ§Ã£o de problemas durante treinamento
   - Arquivo modificado: `src/utils/optuna_optimizer.py`

### Resultados Esperados

**Antes das melhorias:**
- PETR4: 50.57% (com F1=0.0 em folds 2 e 3)
- ITUB4: 52.27%
- VALE3: 53.31%

**Depois das melhorias (esperado):**
- PETR4: 52-54% (sem F1=0.0)
- ITUB4: 54-56%
- VALE3: 55-57%

### Impacto Esperado
- âœ… EliminaÃ§Ã£o de F1=0.0 e MCC=0.0
- âœ… AcurÃ¡cias mais consistentes entre folds
- âœ… Melhor convergÃªncia dos modelos
- âœ… Todas as tÃ©cnicas principais da TCC SeÃ§Ã£o 4.4 implementadas

### Arquivos Modificados
- `src/train.py` - Adicionado cosine scheduler e class weights melhorados
- `src/utils/optuna_optimizer.py` - Mesmas melhorias para otimizaÃ§Ã£o com Optuna

### DocumentaÃ§Ã£o Criada
- `src/documentacao/implementacoes/melhorias_criticas_2026_01_27.md` - DocumentaÃ§Ã£o completa das melhorias

---
