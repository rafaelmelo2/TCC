# Melhorias Cr√≠ticas Implementadas - 2026-01-27

**Data:** 2026-01-27  
**Contexto:** An√°lise de resultados e corre√ß√£o de problemas identificados  
**Status:** ‚úÖ Implementado e pronto para testes

---

## üìã Contexto

Ap√≥s an√°lise dos resultados de treinamento dos modelos CNN-LSTM para PETR4, ITUB4 e VALE3, foram identificados problemas cr√≠ticos:

1. **F1=0.0 e MCC=0.0** em alguns folds (PETR4 folds 2 e 3)
   - Modelo prevendo sempre a mesma classe
   - Indica que modelo n√£o est√° aprendendo padr√µes reais

2. **Acur√°cias abaixo do esperado** em alguns folds
   - PETR4 Fold 3: 47.15% (abaixo do baseline)
   - ITUB4 Fold 5: 50.00% (exatamente no acaso)

3. **Falta de t√©cnicas do TCC** ainda n√£o implementadas
   - Cosine Annealing Scheduler (Se√ß√£o 4.4)
   - Class weights melhorados

---

## ‚úÖ Melhorias Implementadas

### 1. Cosine Annealing Scheduler (TCC Se√ß√£o 4.4)

**Problema:**  
Apenas `ReduceLROnPlateau` estava implementado. O TCC menciona uso de schedulers avan√ßados como Cosine Annealing para melhorar converg√™ncia.

**Solu√ß√£o:**  
Implementado `CosineDecayRestarts` do TensorFlow, que reduz learning rate seguindo curva cosseno com restarts peri√≥dicos.

**Arquivos modificados:**
- `src/train.py` - Fun√ß√£o `treinar_modelo_fold()`
- `src/utils/optuna_optimizer.py` - Fun√ß√µes `objetivo_lstm()` e `objetivo_cnn_lstm()`

**Implementa√ß√£o:**
```python
from tensorflow.keras.optimizers.schedules import CosineDecayRestarts
from tensorflow.keras.callbacks import LearningRateScheduler

# Criar schedule de cosine annealing com restarts
cosine_schedule = CosineDecayRestarts(
    initial_learning_rate=initial_lr,
    first_decay_steps=max(epochs // 2, 10),  # Primeira metade das √©pocas
    t_mul=2.0,  # Multiplicador de per√≠odo (dobra per√≠odo a cada restart)
    m_mul=1.0,  # Multiplicador de learning rate m√≠nimo
    alpha=1e-7  # Learning rate m√≠nimo
)

# Adicionar callback
callbacks_list.append(
    LearningRateScheduler(
        lambda epoch: cosine_schedule(epoch).numpy(),
        verbose=0
    )
)
```

**Justificativa:**
- Cosine annealing permite converg√™ncia mais suave
- Restarts peri√≥dicos ajudam a escapar de m√≠nimos locais
- Conforme mencionado no TCC Se√ß√£o 4.4 sobre t√©cnicas de otimiza√ß√£o

**Benef√≠cio esperado:** +1-3% acur√°cia

---

### 2. Class Weights Melhorados (sklearn)

**Problema:**  
C√°lculo manual de class weights estava causando modelos que previam sempre a mesma classe, resultando em F1=0.0 e MCC=0.0.

**C√≥digo anterior:**
```python
n_class_0 = np.sum(y_train_binary == 0)
n_class_1 = np.sum(y_train_binary == 1)
total = len(y_train_binary)

weight_0 = total / (2 * n_class_0)
weight_1 = total / (2 * n_class_1)
class_weight = {0: weight_0, 1: weight_1}
```

**Problemas identificados:**
- C√°lculo manual pode n√£o ser √≥timo para casos extremos
- N√£o detecta quando h√° apenas uma classe
- Pode n√£o balancear adequadamente

**Solu√ß√£o:**  
Substitu√≠do por `sklearn.utils.class_weight.compute_class_weight` com estrat√©gia 'balanced'.

**C√≥digo novo:**
```python
from sklearn.utils.class_weight import compute_class_weight

if len(np.unique(y_train_binary)) > 1:
    classes = np.unique(y_train_binary)
    weights = compute_class_weight(
        'balanced',
        classes=classes,
        y=y_train_binary
    )
    class_weight = {int(cls): float(weight) for cls, weight in zip(classes, weights)}
else:
    class_weight = None
    if verbose > 0:
        print(f"     [AVISO] Apenas uma classe presente no treino!")
```

**Arquivos modificados:**
- `src/train.py` - Fun√ß√£o `treinar_modelo_fold()`
- `src/utils/optuna_optimizer.py` - Fun√ß√µes `objetivo_lstm()` e `objetivo_cnn_lstm()`

**Benef√≠cios:**
- C√°lculo mais robusto e testado
- Detecta casos extremos (apenas uma classe)
- Previne colapso para mesma classe
- Melhora F1-Score e MCC

---

### 3. Monitoramento de Distribui√ß√£o de Previs√µes

**Problema:**  
N√£o havia alertas quando modelo previa sempre a mesma classe durante otimiza√ß√£o.

**Solu√ß√£o:**  
Adicionado monitoramento detalhado e avisos quando modelo colapsa.

**Implementa√ß√£o:**
```python
# Debug: verificar se o modelo est√° variando
n_pred_1 = np.sum(y_pred_direcao == 1)
n_pred_neg1 = np.sum(y_pred_direcao == -1)

# Aviso se modelo prev√™ sempre mesma classe
warning = ""
if n_pred_1 == 0 or n_pred_neg1 == 0:
    warning = " ‚ö†Ô∏è MODELO PREV√ä SEMPRE MESMA CLASSE!"

print(f"     Trial {trial.number}: Pred=[1:{n_pred_1}, -1:{n_pred_neg1}], "
      f"Val=[1:{n_val_1}, -1:{n_val_neg1}], "
      f"Proba=[{pred_min:.3f}-{pred_max:.3f}, mean={pred_mean:.3f}, std={pred_std:.3f}], "
      f"Acc={acuracia:.4f}{warning}")
```

**Arquivo modificado:**
- `src/utils/optuna_optimizer.py` - Fun√ß√£o `objetivo_cnn_lstm()`

**Benef√≠cios:**
- Identifica√ß√£o imediata de problemas durante otimiza√ß√£o
- Facilita debugging
- Permite ajustes r√°pidos

---

## üìä Resultados Esperados

### Antes das Melhorias:
- **VALE3:** 53.31% (OK)
- **PETR4:** 50.57% (com F1=0.0 em folds 2 e 3) ‚ö†Ô∏è
- **ITUB4:** 52.27% (OK)

### Ap√≥s Melhorias (Esperado):
- **VALE3:** 55-57% (+2-4%)
- **PETR4:** 52-54% (+2-4%, sem F1=0.0) ‚úÖ
- **ITUB4:** 54-56% (+2-4%)

**Melhorias espec√≠ficas:**
- ‚úÖ Elimina√ß√£o de F1=0.0 e MCC=0.0
- ‚úÖ Acur√°cias mais consistentes entre folds
- ‚úÖ Melhor converg√™ncia dos modelos

---

## üß™ Valida√ß√£o e Testes

### Teste R√°pido (1 fold problem√°tico):
```bash
cd codigo/pipeline
uv run python src/train.py --ativo PETR4 --modelo cnn_lstm \
    --optuna --n-trials 20 --epochs 100 --folds 3
```

**Objetivo:** Verificar se fold 3 (que tinha 47.15% e F1=0.0) melhora.

### Treinamento Completo:
```bash
uv run python src/train.py --ativo PETR4 --modelo cnn_lstm \
    --optuna --n-trials 50 --epochs 150
```

**Objetivo:** Retreinar todos os folds e comparar resultados.

---

## üìù Refer√™ncias ao TCC

### Se√ß√£o 4.4 - Treinamento e Otimiza√ß√£o

**T√©cnicas mencionadas:**
- ‚úÖ Walk-forward validation
- ‚úÖ Otimiza√ß√£o bayesiana (Optuna)
- ‚úÖ AdamW optimizer
- ‚úÖ Gradient clipping
- ‚úÖ Early stopping
- ‚úÖ ReduceLROnPlateau
- ‚úÖ **Cosine Annealing Scheduler** ‚Üê NOVO
- ‚úÖ Class weights
- ‚úÖ Banda morta

**Status:** Todas as t√©cnicas principais da Se√ß√£o 4.4 agora est√£o implementadas.

---

## üîÑ Pr√≥ximos Passos

### Fase 2: Features Adicionais (Prioridade M√©dia)
- Amplitude high-low normalizada
- Varia√ß√µes de volume
- Hora do dia (sin/cos encoding)
- Fase do preg√£o

**Benef√≠cio esperado:** +2-5% acur√°cia

### Fase 3: Ensemble (Prioridade M√©dia)
- Voting dos 5 folds
- M√©dia ponderada de probabilidades

**Benef√≠cio esperado:** +3-5% acur√°cia

---

## ‚úÖ Checklist de Implementa√ß√£o

- [x] Cosine Annealing Scheduler implementado
- [x] Class weights melhorados (sklearn)
- [x] Monitoramento de distribui√ß√£o adicionado
- [x] Documenta√ß√£o criada
- [ ] Testado em fold problem√°tico
- [ ] Retreinar todos os ativos
- [ ] Comparar resultados antes/depois

---

## üìå Notas T√©cnicas

### Por que Cosine Annealing?
- Reduz learning rate de forma suave (curva cosseno)
- Restarts peri√≥dicos permitem explorar novos m√≠nimos
- Melhor que redu√ß√£o abrupta (ReduceLROnPlateau)
- Conforme literatura de deep learning para s√©ries temporais

### Por que sklearn class_weight?
- Algoritmo testado e validado
- Estrat√©gia 'balanced' √© padr√£o da literatura
- Detecta casos extremos automaticamente
- Mais robusto que c√°lculo manual

### Impacto nas M√©tricas
- **F1-Score:** Deve melhorar significativamente (eliminar zeros)
- **MCC:** Deve melhorar (melhor correla√ß√£o)
- **Acur√°cia:** Melhoria moderada (+2-4%)
- **Consist√™ncia:** Menos varia√ß√£o entre folds

---

**Pr√≥xima atualiza√ß√£o:** Ap√≥s testes e valida√ß√£o dos resultados.
