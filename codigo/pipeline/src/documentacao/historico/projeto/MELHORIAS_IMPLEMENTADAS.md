# Melhorias Implementadas - 2026-01-27

**Data:** 2026-01-27  
**Status:** Referência (Cosine Annealing, class weights, focal loss, etc.)

---

## 1. Melhorias Críticas Implementadas

### 1. Cosine Annealing Scheduler (TCC Seção 4.4)
**Status:** ✅ Implementado  
**Arquivos modificados:**
- `src/train.py` - Função `treinar_modelo_fold()`
- `src/utils/optuna_optimizer.py` - Funções `objetivo_lstm()` e `objetivo_cnn_lstm()`

**Implementação:**
```python
from tensorflow.keras.optimizers.schedules import CosineDecayRestarts

cosine_schedule = CosineDecayRestarts(
    initial_learning_rate=initial_lr,
    first_decay_steps=max(epochs // 2, 10),
    t_mul=2.0,
    m_mul=1.0,
    alpha=1e-7
)
callbacks_list.append(
    LearningRateScheduler(lambda epoch: cosine_schedule(epoch).numpy())
)
```

**Benefício esperado:** +1-3% acurácia

---

### 2. Class Weights Melhorados (sklearn)
**Status:** ✅ Implementado  
**Problema resolvido:** Modelos prevendo sempre a mesma classe (F1=0.0, MCC=0.0)

**Antes:**
```python
weight_0 = total / (2 * n_class_0)
weight_1 = total / (2 * n_class_1)
```

**Depois:**
```python
from sklearn.utils.class_weight import compute_class_weight

weights = compute_class_weight('balanced', classes=classes, y=y_train_binary)
class_weight = {int(cls): float(weight) for cls, weight in zip(classes, weights)}
```

**Benefício:** Previne colapso para mesma classe, melhora F1-Score e MCC

---

### 3. Monitoramento de Distribuição de Previsões
**Status:** ✅ Implementado  
**Arquivo:** `src/utils/optuna_optimizer.py`

**Adicionado:**
- Aviso quando modelo prevê sempre mesma classe
- Log detalhado de distribuição de previsões vs real

**Exemplo de saída:**
```
Trial 5: Pred=[1:0, -1:716], Val=[1:349, -1:367], ...
⚠️ MODELO PREVÊ SEMPRE MESMA CLASSE!
```

---

## 2. Resultados Esperados

### Antes das Melhorias:
- VALE3: 53.31%
- PETR4: 50.57% (com F1=0.0 em folds 2 e 3)
- ITUB4: 52.27%

### Após Melhorias:
- **Esperado:** +2-4% acurácia média
- **VALE3:** 55-57%
- **PETR4:** 52-54% (sem F1=0.0)
- **ITUB4:** 54-56%

---

## 3. Próximos Passos

### Fase 2: Features Adicionais (Próximo)
1. Amplitude high-low normalizada
2. Variações de volume
3. Hora do dia (sin/cos encoding)
4. Fase do pregão

**Benefício esperado:** +2-5% acurácia

### Fase 3: Ensemble (Depois)
1. Voting dos 5 folds
2. Média ponderada de probabilidades

**Benefício esperado:** +3-5% acurácia

---

## 4. Como Testar

### Teste Rápido (1 fold):
```bash
cd codigo/pipeline
uv run python src/train.py --ativo PETR4 --modelo cnn_lstm --optuna --n-trials 10 --epochs 50 --folds 3
```

### Treinamento Completo:
```bash
uv run python src/train.py --ativo PETR4 --modelo cnn_lstm --optuna --n-trials 50 --epochs 150
```

---

## 5. Notas Técnicas

### Cosine Annealing Scheduler
- Reduz learning rate seguindo curva cosseno
- Permite "restarts" periódicos para escapar de mínimos locais
- Melhora convergência em problemas difíceis

### Class Weights (sklearn balanced)
- Calcula pesos automaticamente baseado em frequência
- Mais robusto que cálculo manual
- Previne overfitting em classe majoritária

---

## 6. Checklist de Validação

- [x] Cosine scheduler implementado
- [x] Class weights melhorados
- [x] Monitoramento adicionado
- [ ] Testado em fold problemático (PETR4 fold 3)
- [ ] Retreinar todos os ativos
- [ ] Comparar resultados antes/depois
