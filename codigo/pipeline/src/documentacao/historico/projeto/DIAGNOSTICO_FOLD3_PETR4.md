# DiagnÃ³stico: Fold 3 PETR4 - Modelo Colapsando

**Data:** 2026-01-27  
**Status:** ReferÃªncia (diagnÃ³stico colapso de classe)  
**Problema:** F1=0.0, MCC=0.0, modelo prevÃª sempre classe -1 (baixa)

---

## 1. EvidÃªncias

### Durante OtimizaÃ§Ã£o (Optuna):
```
Trial 0:  Pred=[1:0, -1:781], std=0.004 âš ï¸ SEMPRE MESMA CLASSE
Trial 5:  Pred=[1:11, -1:770], std=0.004 (quase colapsou)
Trial 10: Pred=[1:0, -1:781], std=0.002 âš ï¸ SEMPRE MESMA CLASSE
Trial 15: Pred=[1:0, -1:781], std=0.000 âš ï¸ TOTALMENTE COLAPSADO
```

### Class Weights Aplicados:
```python
{0: 1.0098669114272603, 1: 0.9903240324032403}
```
â†’ **Quase iguais!** Classes estÃ£o balanceadas no treino.

### Resultado Final:
- AcurÃ¡cia: 47.15% (pior que baseline de 50%)
- F1-Score: 0.0
- MCC: 0.0

---

## 2. AnÃ¡lise

### O que as melhorias NÃƒO resolveram:
1. âœ… Cosine Annealing Scheduler â†’ Implementado mas nÃ£o ajudou
2. âœ… Class weights (sklearn) â†’ Calculados corretamente mas sÃ£o quase iguais
3. âœ… Monitoramento â†’ Funcionou, detectou o problema

### Causa Raiz:
**O problema NÃƒO Ã© tÃ©cnico (class weights, scheduler), Ã© do PERÃODO:**

1. **PerÃ­odo extremamente difÃ­cil**: Fold 3 pode ter comportamento de mercado anÃ´malo
2. **Features sem poder preditivo**: Indicadores tÃ©cnicos nÃ£o funcionam neste perÃ­odo
3. **Modelo nÃ£o encontra padrÃµes**: Converge para "sempre baixa" como melhor estratÃ©gia

### Por que o modelo prevÃª sempre "baixa"?
- Durante treino, aprende que no **conjunto de teste** deste fold, a classe majoritÃ¡ria Ã© "baixa"
- Como nÃ£o encontra padrÃµes reais, usa esta estratÃ©gia trivial
- Isso dÃ¡ ~47% porque no teste hÃ¡ ~47% de baixas

---

## 3. SoluÃ§Ãµes Propostas

### 1. Focal Loss (CRÃTICO) ðŸ”´
**O que Ã©:** Loss que penaliza mais erros em exemplos difÃ­ceis

**Por que ajuda:** 
- ForÃ§a modelo a aprender ambas as classes
- NÃ£o permite colapso para uma classe

**ImplementaÃ§Ã£o:**
```python
def focal_loss(gamma=2.0, alpha=0.25):
    def focal_loss_fixed(y_true, y_pred):
        epsilon = K.epsilon()
        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)
        p_t = tf.where(K.equal(y_true, 1), y_pred, 1 - y_pred)
        alpha_t = tf.where(K.equal(y_true, 1), alpha, 1 - alpha)
        focal_weight = alpha_t * K.pow((1 - p_t), gamma)
        loss = -focal_weight * K.log(p_t)
        return K.mean(loss)
    return focal_loss_fixed

# Usar na compilaÃ§Ã£o:
model.compile(loss=focal_loss(gamma=2.0), ...)
```

**BenefÃ­cio esperado:** Elimina F1=0.0, melhora +3-5%

### 2. Aumento Manual de Peso da Classe MinoritÃ¡ria ðŸŸ¡
**O que fazer:**
- Multiplicar peso da classe minoritÃ¡ria por 2-3x
- ForÃ§ar modelo a dar mais atenÃ§Ã£o Ã  classe que estÃ¡ ignorando

**ImplementaÃ§Ã£o:**
```python
if len(np.unique(y_train_binary)) > 1:
    weights = compute_class_weight('balanced', classes=classes, y=y_train_binary)
    # AUMENTAR peso da classe minoritÃ¡ria
    class_weight = {
        0: float(weights[0]) * 2.0,  # Dobrar peso de "baixa"
        1: float(weights[1]) * 2.0   # Dobrar peso de "alta"
    }
```

### 3. Early Stopping por DistribuiÃ§Ã£o ðŸŸ¡
**O que fazer:**
- Durante treinamento, verificar se modelo prevÃª ambas as classes
- Parar se 95%+ das previsÃµes sÃ£o da mesma classe

**ImplementaÃ§Ã£o:**
```python
class DistributionCallback(keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        y_pred = self.model.predict(X_val, verbose=0)
        n_high = np.sum(y_pred > 0.5)
        n_low = np.sum(y_pred <= 0.5)
        
        if n_high == 0 or n_low == 0:
            print(f"\nâš ï¸ Modelo colapsou! Parando treino...")
            self.model.stop_training = True
```

### 4. Features Temporais Adicionais ðŸŸ¢
**O que adicionar:**
- Hora do dia (sin/cos encoding)
- Dia da semana
- DistÃ¢ncia da abertura/fechamento
- Indicador de volatilidade extrema

**BenefÃ­cio:** +2-5% acurÃ¡cia (mas nÃ£o resolve fold 3)

### 5. Data Augmentation (SMOTE/ADASYN) ðŸŸ¢
**O que fazer:**
- Gerar exemplos sintÃ©ticos da classe minoritÃ¡ria
- Apenas para folds problemÃ¡ticos

**ImplementaÃ§Ã£o:**
```python
from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(
    X_train_filtered.reshape(len(X_train_filtered), -1),
    y_train_binary
)
```

---

## 4. Plano de AÃ§Ã£o Recomendado

### Prioridade ALTA (Fazer AGORA):
1. **Implementar Focal Loss** â† Mais importante
2. Testar em fold 3 do PETR4

### Prioridade MÃ‰DIA (Fazer depois):
3. Aumentar weight da classe minoritÃ¡ria manualmente
4. Implementar early stopping por distribuiÃ§Ã£o
5. Adicionar features temporais

### Prioridade BAIXA:
6. SMOTE/data augmentation (complexo, pode causar overfitting)

---

## 5. Expectativa Realista

### Com Focal Loss:
- Fold 3 PETR4: 47.15% â†’ **50-52%** (esperado)
- F1-Score: 0.0 â†’ **0.3-0.5**
- MCC: 0.0 â†’ **0.05-0.15**

**IMPORTANTE:** Fold 3 pode ser genuinamente difÃ­cil. Mesmo com todas as tÃ©cnicas, pode nÃ£o superar 52-53%.

### Literatura:
- Nem todos os perÃ­odos sÃ£o previsÃ­veis
- Alguns folds terÃ£o performance prÃ³xima do acaso
- Isso Ã© **normal e aceitÃ¡vel** em finanÃ§as quantitativas

---

## 6. Notas TÃ©cnicas

### Por que Focal Loss funciona?
- Binary crossentropy trata todos os exemplos igualmente
- Focal Loss foca em exemplos difÃ­ceis e mal classificados
- ForÃ§a modelo a nÃ£o ignorar classe minoritÃ¡ria

### Quando usar?
- Problemas com classes desbalanceadas
- Modelos que colapsam para uma classe
- Quando class weights nÃ£o sÃ£o suficientes

### ReferÃªncias:
- Lin et al. (2017): "Focal Loss for Dense Object Detection"
- Usado em computer vision, mas aplicÃ¡vel a sÃ©ries temporais
