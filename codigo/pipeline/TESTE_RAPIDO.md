# Teste R√°pido de Valida√ß√£o - Passo a Passo

**Data:** 2026-01-23  
**Objetivo:** Testar melhorias antes de rodar treinamento completo durante a noite

---

## üéØ Estrat√©gia

1. **Teste R√°pido** (~30 min): 10 trials, poucos folds
2. **An√°lise**: Script autom√°tico decide se prosseguir
3. **Treinamento Completo** (√† noite): 50 trials, 5 folds

---

## üìã Passo 1: Executar Teste R√°pido

```bash
cd ~/Arquivos/TCC/codigo/pipeline

# Teste r√°pido: 10 trials do Optuna
uv run python src/train.py \
    --ativo VALE3 \
    --modelo cnn_lstm \
    --optuna \
    --n-trials 10 \
    --epochs 100
```

**Tempo estimado:** 30-40 minutos  
**O que faz:** Treina 2 primeiros folds com 10 trials de otimiza√ß√£o

---

## üìä Passo 2: Analisar Resultados

### Op√ß√£o A: Script Autom√°tico (RECOMENDADO)

```bash
# Ap√≥s o teste terminar
uv run python src/scripts/teste_rapido_validacao.py --ativo VALE3 --modelo cnn_lstm
```

**Sa√≠da esperada:**
```
==================================================
AN√ÅLISE DO TESTE R√ÅPIDO
==================================================

Resultados encontrados: 2 folds
   fold  accuracy_direcional  accuracy  f1_score    mcc
1     1            0.505000  0.505000  0.630000  0.055
2     2            0.535000  0.535000  0.590000  0.068

==================================================
CRIT√âRIOS DE APROVA√á√ÉO
==================================================
  ‚úÖ Acur√°cia m√©dia: 0.5200 > 0.51
  ‚úÖ Fold 1: 0.5050 > 0.4687 (baseline)
  ‚úÖ MCC m√©dio: 0.0615 > 0.0390 (baseline)
  ‚úÖ F1-Score m√©dio: 0.6100 > 0.55
  ‚úÖ Variabilidade: 0.0212 < 0.10 (est√°vel)
  ‚úÖ Modelos salvos: 2 arquivos

==================================================
‚úÖ TESTE APROVADO - Pode prosseguir!
==================================================

Comando para treinamento completo (rodar √† noite):

uv run python src/train.py \
    --ativo VALE3 \
    --modelo cnn_lstm \
    --optuna \
    --n-trials 50 \
    --epochs 150
```

### Op√ß√£o B: An√°lise Manual

```bash
# Ver resultados
cat data/processed/VALE3_cnn_lstm_walkforward.csv

# Verificar modelos salvos
ls -lh models/VALE3/cnn_lstm/
```

---

## ‚úÖ Crit√©rios de Aprova√ß√£o

O teste √© **APROVADO** se:

| Crit√©rio | Valor Esperado | Baseline Atual |
|----------|----------------|----------------|
| Acur√°cia m√©dia | > 51% | 52.51% |
| Fold 1 | > 48% | 46.87% |
| MCC m√©dio | > 0.04 | 0.039 |
| F1-Score | > 0.55 | 0.626 |
| Modelos salvos | 2 arquivos | - |

**Sinais de progress√£o:**
- ‚úÖ Fold 1 melhor que antes (46.87%)
- ‚úÖ MCC n√£o √© zero
- ‚úÖ Trials convergindo sem NaN
- ‚úÖ Previs√µes n√£o totalmente desbalanceadas

---

## üöÄ Passo 3A: SE APROVADO - Rodar Completo

```bash
# Copiar e colar para rodar durante a noite
cd ~/Arquivos/TCC/codigo/pipeline

# Treinamento completo
nohup uv run python src/train.py \
    --ativo VALE3 \
    --modelo cnn_lstm \
    --optuna \
    --n-trials 50 \
    --epochs 150 \
    > logs/treinamento_completo_$(date +%Y%m%d_%H%M%S).log 2>&1 &

# Ver processo rodando
ps aux | grep train.py

# Acompanhar logs em tempo real
tail -f logs/treinamento_completo_*.log
```

**Tempo estimado:** 3-4 horas  
**Meta:** Acur√°cia 54-56%, MCC > 0.08

**Manh√£ seguinte:**
```bash
# Ver resultados
cat data/processed/VALE3_cnn_lstm_walkforward.csv

# Analisar modelos salvos
uv run python src/scripts/analisar_modelos_salvos.py --ativo VALE3 --modelo cnn_lstm
```

---

## üîç Passo 3B: SE REPROVADO - Investigar

### Problemas Poss√≠veis

#### Problema 1: Fold 1 ainda muito baixo (< 48%)

**Poss√≠veis causas:**
- Dados do Fold 1 t√™m regime diferente
- Hiperpar√¢metros n√£o adequados
- Banda morta muito agressiva

**Solu√ß√µes:**
```python
# Op√ß√£o A: Aumentar threshold da banda morta
# Em config.py: THRESHOLD_BANDA_MORTA = 0.0015 (de 0.001)

# Op√ß√£o B: Ajustar espa√ßo de busca do Optuna
# Em optuna_optimizer.py: aumentar range de learning_rate
```

#### Problema 2: MCC = 0.0 persistente

**Poss√≠veis causas:**
- Modelo prevendo sempre mesma classe
- Class weights n√£o funcionando
- Valida√ß√£o interna desbalanceada

**Solu√ß√µes:**
```python
# Verificar distribui√ß√£o de previs√µes
# Ajustar class_weight no train.py
# Usar focal loss ao inv√©s de binary crossentropy
```

#### Problema 3: Trials explodindo (NaN, loss infinito)

**Poss√≠veis causas:**
- Learning rate muito alto
- Gradient clipping insuficiente
- Batch size muito pequeno

**Solu√ß√µes:**
```python
# Op√ß√£o A: Reduzir max learning rate
# Em optuna_optimizer.py: learning_rate = trial.suggest_float(..., 1e-4, 5e-3)

# Op√ß√£o B: Aumentar gradient clipping
# Em cnn_lstm_model.py: gradient_clip_norm=0.5
```

#### Problema 4: Modelos n√£o sendo salvos

**Poss√≠veis causas:**
- Erro de permiss√£o
- Diret√≥rio n√£o criado
- Callback n√£o configurado

**Solu√ß√µes:**
```bash
# Criar diret√≥rio manualmente
mkdir -p models/VALE3/cnn_lstm

# Verificar permiss√µes
ls -la models/
```

---

## üìù Checklist de Execu√ß√£o

**Antes de dormir:**
- [ ] Executei teste r√°pido (10 trials)
- [ ] Analisei resultados com script
- [ ] Teste foi APROVADO
- [ ] Iniciei treinamento completo com `nohup`
- [ ] Verifiquei que processo est√° rodando
- [ ] Verifiquei logs iniciais (sem erros)

**Ao acordar:**
- [ ] Verificar se processo terminou (`ps aux | grep train`)
- [ ] Ver resultados finais (`cat data/processed/VALE3_cnn_lstm_walkforward.csv`)
- [ ] Analisar modelos salvos (script de an√°lise)
- [ ] Comparar com baseline (52.51%)

---

## üéØ Resultados Esperados

### Teste R√°pido (2 folds)

| M√©trica | Baseline | Meta Teste |
|---------|----------|------------|
| Acur√°cia Fold 1 | 46.87% | > 50% |
| Acur√°cia Fold 2 | 52.45% | > 53% |
| MCC m√©dio | 0.039 | > 0.05 |

### Treinamento Completo (5 folds)

| M√©trica | Baseline | Meta Completo |
|---------|----------|---------------|
| Acur√°cia m√©dia | 52.51% | 54-56% |
| MCC m√©dio | 0.039 | > 0.08 |
| F1-Score | 0.626 | > 0.65 |
| Melhor fold | 56.82% | > 58% |

---

## üõ†Ô∏è Comandos de Emerg√™ncia

### Se o treinamento travar

```bash
# Ver processos Python
ps aux | grep python

# Matar processo (substituir PID)
kill -9 <PID>

# Ver uso de GPU
nvidia-smi
```

### Se ficar sem espa√ßo

```bash
# Ver espa√ßo
df -h

# Limpar cache do TensorFlow
rm -rf ~/.keras/

# Limpar modelos antigos (CUIDADO!)
# rm -rf models/VALE3_old/
```

### Backup de seguran√ßa

```bash
# Antes de dormir, fazer backup dos modelos atuais
cp -r models/VALE3 models/VALE3_backup_$(date +%Y%m%d)
```

---

## üìû Troubleshooting

### Erro: "Out of memory (GPU)"

```bash
# Reduzir batch size
uv run python src/train.py ... --batch-size 16  # (padr√£o: 32)
```

### Erro: "No module named 'optuna'"

```bash
# Reinstalar depend√™ncias
uv sync
```

### Erro: "Permission denied" ao salvar modelo

```bash
# Criar diret√≥rios com permiss√µes
mkdir -p models/VALE3/cnn_lstm
chmod -R 755 models/
```

---

## üìä Monitoramento em Tempo Real

### Terminal 1: Logs

```bash
tail -f logs/treinamento_completo_*.log
```

### Terminal 2: GPU

```bash
watch -n 1 nvidia-smi
```

### Terminal 3: Resultados parciais

```bash
watch -n 10 "cat data/processed/VALE3_cnn_lstm_walkforward.csv"
```

---

## ‚úÖ Conclus√£o

**Fluxo completo:**

1. **Agora:** Teste r√°pido (30 min)
2. **Analise:** Script autom√°tico
3. **Se OK:** Rodar completo durante a noite
4. **Manh√£:** Verificar resultados e decidir pr√≥ximos passos

**Meta final:** 54-56% de acur√°cia com modelos salvos!

---

**√öltima atualiza√ß√£o:** 2026-01-23  
**Pr√≥ximo passo:** Executar teste r√°pido
