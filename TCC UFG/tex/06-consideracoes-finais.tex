
O trabalho até aqui forneceu uma definição sistemática de escopo, objetivos e planejamento metodológico para uma tarefa de previsão direcional intradiária na B3, especificamente em uma proposta forte para uma avaliação completa e reprodutível. O principal objetivo foi fornecer um protocolo sensível ao tempo que não vaze informações e represente melhor o uso real com custos e slippage. Para alcançar isso, o plano integrou:

\begin{enumerate}[label=\roman*.]
\item construção do banco de dados intradiário;
\item configuração experimental com janelas deslizantes e validação cruzada walk-forward com embargo temporal; 
\item comparação de linhas de base (por exemplo, ARIMA e LSTM) com as redes propostas;
\item definição de métricas relacionadas à tomada de decisão;
\item backtests usando custos explícitos;
\item testes de robustez e significância; e
\item reprodutibilidade, por meio de versionamento e scripts executáveis.
\end{enumerate}

Quanto à base teórico-empírica agora consolidada, o artigo fundamentou-se na dinâmica intradiária (liquidez, volatilidade, volume) e microestrutura, e na decisão de introduzir uma banda morta (positiva) para mitigar ruídos na estimativa da precisão direcional. A revisão apresentou a evolução dos modelos, começando pelos clássicos (como a família ARIMA, modelos Box-Jenkins) até métodos de aprendizado profundo (LSTM, CNN) e arquiteturas contemporâneas com mecanismos de atenção, apontando as limitações de modelos puramente lineares em ambientes não estacionários e na presença de choques, e os ganhos de modelos que lidam com dependência de longo prazo. Além disso, foi mencionada a relevância dos Transformers para séries financeiras multivariadas e de alta frequência, como o TF-T, e algumas evidências de ganhos sobre o LSTM no RMSE e precisão direcional são encontradas sob tamanho de janela longo. O estudo também empregou um modelo híbrido LSTM+CNN como referência para capturar características temporais e locais das características intradiárias, consistente com a intenção de generalidade em vários ambientes de volatilidade.

Para avaliação, uma gama de métricas de decisão e probabilidade foi incluída: precisão direcional com folga (foco principal), qualidade probabilística (Brier Score, Log-Loss e ECE) e medidas de equilíbrio (Balanced Accuracy, F1, MCC, AUC-PR). A validação econômica foi adicionada com backtests com custo e slippage em Peso, retornando retorno líquido, índice de Sharpe, máximo drawdown e fator de lucro de acordo com estruturas operacionais e custos divulgados pela B3. A significância da diferença entre os modelos será examinada através da estatística de Diebold--Mariano, onde a análise é segmentada de acordo com regimes de volatilidade para garantir a robustez da comparação. Por fim, a reprodutibilidade foi garantida pelo versionamento completo de dados, código, artefatos e seeds com scripts de ponta a ponta para preparar, treinar, avaliar e realizar backtests.

A motivação do tema surge do fato de que observamos consistentemente o desempenho em laboratório e o desempenho no piso em desacordo um com o outro em um mundo intradiário ruidoso com custos. O plano metodológico tenta reduzir essa lacuna integrando walk-forward com prevenção de vazamento de embargo, métricas orientadas para decisão e backtests pós-custo e entregar critérios de validação mais robustos enquanto preserva a possibilidade de generalização entre ativos e estados de mercado. As ameaças à validade (qualidade dos dados, viés de sobrevivência, divisões temporais) e mitigadores de resultados também foram claramente declarados, aumentando a confiabilidade do desenho experimental.

Para concluir, as ações subsequentes, explicadas no Capítulo de próximos passos -- posse/limpeza dos dados intradiários, pré-processamento de dados e geração de características, configuração de arquiteturas (linhas de base e propostas), definição do espaço de busca de hiperparâmetros, protocolo de treino/validação walk-forward com embargo e avaliações de métricas e backtests com testes de robustez e significância -- são o elo imediato para o PFC2. Realizar essas etapas na próxima fase torna possível (1) realizar os experimentos sob controles claros, (2) comparar os diferentes modelos de forma estatisticamente significativa, (3) relatar os resultados de forma tão transparente e reprodutível quanto desejado, fechando o ciclo metodológico conforme pretendido neste trabalho.